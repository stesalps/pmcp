{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stesalps/pmcp/blob/main/Google_Manus_System_Complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# ü§ñ Google Manus System (Complete Version)\n",
        "\n",
        "A powerful AI assistant system that leverages Google's local models in Colab for code generation, execution, research, and web deployment, with human-in-the-loop capabilities.\n",
        "\n",
        "## Features\n",
        "\n",
        "- üß† Uses Google's local models (Gemini, Gemma) with fallback to Ollama\n",
        "- üíª Code generation, execution, and review\n",
        "- üîç Research and information retrieval\n",
        "- üåê Web deployment with FRP tunneling\n",
        "- üë§ Human-in-the-loop review system\n",
        "- üõ†Ô∏è Extensible tool system\n",
        "\n",
        "## How to Use\n",
        "\n",
        "1. Run Box 1 to set up the environment\n",
        "2. Run Box 2 to initialize the model system\n",
        "3. Run Box 3 to set up the tool registry\n",
        "4. Run Box 4 to launch the user interface\n",
        "5. Run Box 5 to set up web deployment\n",
        "6. Run Box 6 to enable human-in-the-loop capabilities\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "box1-header"
      },
      "source": [
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "# ‚ïë üîß BOX 1: Environment Setup and Configuration - v1.0                                                     ‚ïë\n",
        "# ‚ïë                                                                                                          ‚ïë\n",
        "# ‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CORE FEATURES ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n",
        "# ‚ïë - System initialization and dependency installation                                                      ‚ïë\n",
        "# ‚ïë - Configuration management and directory structure setup                                                 ‚ïë\n",
        "# ‚ïë - Environment detection (Colab, local)                                                                   ‚ïë\n",
        "# ‚ïë - Logging and error handling                                                                             ‚ïë\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "box1-code"
      },
      "outputs": [],
      "source": [
        "print(\"üîß BOX 1: Initializing Environment Setup and Configuration...\")\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import logging\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any, Optional, Union, Callable\n",
        "\n",
        "# Check if running in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IS_COLAB = True\n",
        "    print(\"‚úÖ Running in Google Colab environment\")\n",
        "except ImportError:\n",
        "    IS_COLAB = False\n",
        "    print(\"‚ÑπÔ∏è Running in local environment\")\n",
        "\n",
        "# Define base directories\n",
        "if IS_COLAB:\n",
        "    # Check if Google Drive is mounted\n",
        "    if not os.path.exists(\"/content/drive\"):\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        print(\"‚úÖ Google Drive mounted\")\n",
        "    \n",
        "    # Use Google Drive for persistence if available\n",
        "    BASE_DIR = Path(\"/content/drive/MyDrive/GoogleManusSystem\")\n",
        "    if not BASE_DIR.exists():\n",
        "        BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "        print(f\"‚úÖ Created base directory at {BASE_DIR}\")\n",
        "    \n",
        "    # Local working directory for temporary files\n",
        "    WORKING_DIR = Path(\"/content/GoogleManusSystem\")\n",
        "else:\n",
        "    # Local environment setup\n",
        "    BASE_DIR = Path(os.getcwd()) / \"GoogleManusSystem\"\n",
        "    WORKING_DIR = BASE_DIR\n",
        "\n",
        "# Create necessary subdirectories\n",
        "WORKSPACE_DIR = BASE_DIR / \"workspace\"\n",
        "CONFIG_DIR = BASE_DIR / \"config\"\n",
        "LOGS_DIR = BASE_DIR / \"logs\"\n",
        "TOOLS_DIR = BASE_DIR / \"tools\"\n",
        "SITES_DIR = BASE_DIR / \"sites\"\n",
        "HUMAN_REVIEW_DIR = BASE_DIR / \"human_review\"\n",
        "\n",
        "for directory in [WORKSPACE_DIR, CONFIG_DIR, LOGS_DIR, TOOLS_DIR, SITES_DIR, HUMAN_REVIEW_DIR]:\n",
        "    directory.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"‚úÖ Ensured directory exists: {directory}\")\n",
        "\n",
        "# Setup logging\n",
        "LOG_FILE = LOGS_DIR / \"manus_log.json\"\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(\"GoogleManus\")\n",
        "\n",
        "# Function to log events in JSON format\n",
        "def log_event(event_type: str, details: Dict[str, Any]) -> None:\n",
        "    \"\"\"Log an event to the JSON log file.\"\"\"\n",
        "    event = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"type\": event_type,\n",
        "        **details\n",
        "    }\n",
        "    \n",
        "    # Append to log file\n",
        "    with open(LOG_FILE, \"a\") as f:\n",
        "        f.write(json.dumps(event) + \"\\n\")\n",
        "    \n",
        "    # Also log to console\n",
        "    logger.info(f\"{event_type}: {details}\")\n",
        "\n",
        "# Install required dependencies\n",
        "required_packages = [\n",
        "    \"fastapi\",\n",
        "    \"uvicorn\",\n",
        "    \"pydantic\",\n",
        "    \"requests\",\n",
        "    \"nest_asyncio\",\n",
        "    \"ipywidgets\",\n",
        "    \"beautifulsoup4\",\n",
        "    \"markdown\",\n",
        "    \"python-multipart\",\n",
        "    \"aiohttp\",\n",
        "    \"websockets\"\n",
        "]\n",
        "\n",
        "print(\"üì¶ Installing required packages...\")\n",
        "for package in required_packages:\n",
        "    try:\n",
        "        __import__(package.split(\"==\")[0].strip())\n",
        "        print(f\"‚úÖ {package} already installed\")\n",
        "    except ImportError:\n",
        "        print(f\"‚è≥ Installing {package}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "        print(f\"‚úÖ Installed {package}\")\n",
        "\n",
        "# Apply nest_asyncio for Jupyter compatibility\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "print(\"‚úÖ Applied nest_asyncio for Jupyter compatibility\")\n",
        "\n",
        "# Create or load configuration\n",
        "config_file = CONFIG_DIR / \"system_config.json\"\n",
        "if config_file.exists():\n",
        "    with open(config_file, \"r\") as f:\n",
        "        config = json.load(f)\n",
        "    print(\"‚úÖ Loaded existing configuration\")\n",
        "else:\n",
        "    # Default configuration\n",
        "    config = {\n",
        "        \"version\": \"1.0.0\",\n",
        "        \"created_at\": datetime.now().isoformat(),\n",
        "        \"updated_at\": datetime.now().isoformat(),\n",
        "        \"default_model\": \"google/gemini-2.5-pro\",\n",
        "        \"default_model_type\": \"google\",\n",
        "        \"workspace_path\": str(WORKSPACE_DIR),\n",
        "        \"log_path\": str(LOG_FILE),\n",
        "        \"sites_path\": str(SITES_DIR),\n",
        "        \"human_review_path\": str(HUMAN_REVIEW_DIR),\n",
        "        \"is_colab\": IS_COLAB,\n",
        "        \"human_review_enabled\": True,\n",
        "        \"auto_approve_threshold\": 0.8,\n",
        "        \"public_url\": None,\n",
        "        \"dashboard_url\": None\n",
        "    }\n",
        "    \n",
        "    with open(config_file, \"w\") as f:\n",
        "        json.dump(config, f, indent=2)\n",
        "    print(\"‚úÖ Created new configuration\")\n",
        "\n",
        "# Export configuration for other boxes\n",
        "box1_exports = {\n",
        "    \"BASE_DIR\": str(BASE_DIR),\n",
        "    \"WORKSPACE_DIR\": str(WORKSPACE_DIR),\n",
        "    \"CONFIG_DIR\": str(CONFIG_DIR),\n",
        "    \"LOGS_DIR\": str(LOGS_DIR),\n",
        "    \"TOOLS_DIR\": str(TOOLS_DIR),\n",
        "    \"SITES_DIR\": str(SITES_DIR),\n",
        "    \"HUMAN_REVIEW_DIR\": str(HUMAN_REVIEW_DIR),\n",
        "    \"LOG_FILE\": str(LOG_FILE),\n",
        "    \"IS_COLAB\": IS_COLAB,\n",
        "    \"config\": config\n",
        "}\n",
        "\n",
        "box1_exports_file = CONFIG_DIR / \"box1_exports.json\"\n",
        "with open(box1_exports_file, \"w\") as f:\n",
        "    json.dump(box1_exports, f, indent=2)\n",
        "\n",
        "print(\"\\nüéâ BOX 1 SETUP COMPLETED SUCCESSFULLY!\")\n",
        "print(f\"üìÅ Base Directory: {BASE_DIR}\")\n",
        "print(f\"üíæ Configuration: {config_file}\")\n",
        "print(f\"üìù Log File: {LOG_FILE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "box2-header"
      },
      "source": [
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "# ‚ïë üß† BOX 2: Model Integration and Core Services - v1.0                                                     ‚ïë\n",
        "# ‚ïë                                                                                                          ‚ïë\n",
        "# ‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CORE FEATURES ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n",
        "# ‚ïë - Google model integration (Gemini, Gemma)                                                               ‚ïë\n",
        "# ‚ïë - Ollama model integration (fallback)                                                                    ‚ïë\n",
        "# ‚ïë - Model selection and configuration                                                                      ‚ïë\n",
        "# ‚ïë - Streaming response handling                                                                            ‚ïë\n",
        "# ‚ïë - Context and memory management                                                                          ‚ïë\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "box2-code"
      },
      "outputs": [],
      "source": [
        "print(\"üß† BOX 2: Initializing Model Integration and Core Services...\")\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import asyncio\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any, Optional, Union, Callable, Generator, Tuple\n",
        "\n",
        "# Load configuration from Box 1\n",
        "try:\n",
        "    with open(Path(\"./GoogleManusSystem/config/box1_exports.json\"), \"r\") as f:\n",
        "        box1_exports = json.load(f)\n",
        "    \n",
        "    # Extract paths and configuration\n",
        "    BASE_DIR = Path(box1_exports[\"BASE_DIR\"])\n",
        "    CONFIG_DIR = Path(box1_exports[\"CONFIG_DIR\"])\n",
        "    IS_COLAB = box1_exports[\"IS_COLAB\"]\n",
        "    config = box1_exports[\"config\"]\n",
        "    \n",
        "    print(\"‚úÖ Loaded configuration from Box 1\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading Box 1 configuration: {e}\")\n",
        "    print(\"‚ö†Ô∏è Using default configuration\")\n",
        "    \n",
        "    # Default configuration if Box 1 hasn't been run\n",
        "    BASE_DIR = Path(\"./GoogleManusSystem\")\n",
        "    CONFIG_DIR = BASE_DIR / \"config\"\n",
        "    IS_COLAB = True\n",
        "    config = {\n",
        "        \"default_model\": \"google/gemini-2.5-pro\",\n",
        "        \"default_model_type\": \"google\",\n",
        "        \"human_review_enabled\": True,\n",
        "        \"auto_approve_threshold\": 0.8\n",
        "    }\n",
        "\n",
        "# Import Google Colab AI module\n",
        "try:\n",
        "    from google.colab import ai\n",
        "    GOOGLE_AI_AVAILABLE = True\n",
        "    print(\"‚úÖ Google Colab AI module imported successfully\")\n",
        "except ImportError:\n",
        "    GOOGLE_AI_AVAILABLE = False\n",
        "    print(\"‚ö†Ô∏è Google Colab AI module not available. Will use fallback mode.\")\n",
        "\n",
        "# Check for Ollama availability\n",
        "OLLAMA_AVAILABLE = False\n",
        "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
        "try:\n",
        "    response = requests.get(\"http://localhost:11434/api/tags\")\n",
        "    if response.status_code == 200:\n",
        "        OLLAMA_AVAILABLE = True\n",
        "        print(\"‚úÖ Ollama is available\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è Ollama is not available. Will use Google models only.\")\n",
        "\n",
        "# Get available Google models\n",
        "if GOOGLE_AI_AVAILABLE:\n",
        "    try:\n",
        "        google_models = ai.list_models()\n",
        "        print(f\"‚úÖ Available Google models: {google_models}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error listing Google models: {e}\")\n",
        "        google_models = [\n",
        "            \"google/gemini-2.0-flash\",\n",
        "            \"google/gemini-2.0-flash-lite\",\n",
        "            \"google/gemini-2.5-flash\",\n",
        "            \"google/gemini-2.5-flash-lite\",\n",
        "            \"google/gemini-2.5-pro\",\n",
        "            \"google/gemma-3-12b\",\n",
        "            \"google/gemma-3-1b\",\n",
        "            \"google/gemma-3-27b\",\n",
        "            \"google/gemma-3-4b\"\n",
        "        ]\n",
        "else:\n",
        "    # Fallback model list\n",
        "    google_models = [\n",
        "        \"google/gemini-2.0-flash\",\n",
        "        \"google/gemini-2.0-flash-lite\",\n",
        "        \"google/gemini-2.5-flash\",\n",
        "        \"google/gemini-2.5-flash-lite\",\n",
        "        \"google/gemini-2.5-pro\",\n",
        "        \"google/gemma-3-12b\",\n",
        "        \"google/gemma-3-1b\",\n",
        "        \"google/gemma-3-27b\",\n",
        "        \"google/gemma-3-4b\"\n",
        "    ]\n",
        "\n",
        "# Get available Ollama models\n",
        "ollama_models = []\n",
        "if OLLAMA_AVAILABLE:\n",
        "    try:\n",
        "        response = requests.get(\"http://localhost:11434/api/tags\")\n",
        "        if response.status_code == 200:\n",
        "            ollama_models = [model[\"name\"] for model in response.json().get(\"models\", [])]\n",
        "            print(f\"‚úÖ Available Ollama models: {ollama_models}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error listing Ollama models: {e}\")\n",
        "        ollama_models = [\"llama3\", \"mistral\", \"gemma\"]\n",
        "\n",
        "# Set default model\n",
        "default_model = config.get(\"default_model\", \"google/gemini-2.5-pro\")\n",
        "default_model_type = config.get(\"default_model_type\", \"google\")\n",
        "\n",
        "if default_model_type == \"google\" and default_model not in google_models:\n",
        "    default_model = google_models[0] if google_models else None\n",
        "    print(f\"‚ö†Ô∏è Default Google model not available. Using {default_model} instead.\")\n",
        "elif default_model_type == \"ollama\" and default_model not in ollama_models:\n",
        "    default_model = ollama_models[0] if ollama_models else None\n",
        "    print(f\"‚ö†Ô∏è Default Ollama model not available. Using {default_model} instead.\")\n",
        "\n",
        "# If no models are available, set fallback mode\n",
        "if not GOOGLE_AI_AVAILABLE and not OLLAMA_AVAILABLE:\n",
        "    print(\"‚ö†Ô∏è No AI models available. Using fallback mode.\")\n",
        "    default_model_type = \"fallback\"\n",
        "    default_model = \"fallback\"\n",
        "elif not default_model:\n",
        "    if GOOGLE_AI_AVAILABLE:\n",
        "        default_model_type = \"google\"\n",
        "        default_model = google_models[0]\n",
        "    elif OLLAMA_AVAILABLE:\n",
        "        default_model_type = \"ollama\"\n",
        "        default_model = ollama_models[0]\n",
        "\n",
        "print(f\"‚úÖ Using default model type: {default_model_type}\")\n",
        "print(f\"‚úÖ Using default model: {default_model}\")\n",
        "\n",
        "# Model adapter for unified access to Google and Ollama models\n",
        "class ModelAdapter:\n",
        "    def __init__(self, default_model_type=\"google\", default_google_model=None, default_ollama_model=None):\n",
        "        self.default_model_type = default_model_type\n",
        "        self.default_google_model = default_google_model or (google_models[0] if google_models else None)\n",
        "        self.default_ollama_model = default_ollama_model or (ollama_models[0] if ollama_models else None)\n",
        "        self.ollama_url = \"http://localhost:11434/api/generate\"\n",
        "    \n",
        "    async def generate_response(self, prompt: str, model_type: str = None, model_name: str = None, \n",
        "                               stream: bool = False) -> Union[str, Generator, Tuple[str, float]]:\n",
        "        \"\"\"Generate a response using the specified model.\n",
        "        \n",
        "        Args:\n",
        "            prompt: The input prompt\n",
        "            model_type: The type of model to use (google, ollama, or fallback)\n",
        "            model_name: The specific model name\n",
        "            stream: Whether to stream the response\n",
        "            \n",
        "        Returns:\n",
        "            Generated text or a generator for streaming, with confidence score\n",
        "        \"\"\"\n",
        "        model_type = model_type or self.default_model_type\n",
        "        \n",
        "        if model_type == \"google\" and GOOGLE_AI_AVAILABLE:\n",
        "            model_name = model_name or self.default_google_model\n",
        "            return await self._generate_google_response(prompt, model_name, stream)\n",
        "        elif model_type == \"ollama\" and OLLAMA_AVAILABLE:\n",
        "            model_name = model_name or self.default_ollama_model\n",
        "            return await self._generate_ollama_response(prompt, model_name, stream)\n",
        "        else:\n",
        "            # Fallback to available model\n",
        "            if GOOGLE_AI_AVAILABLE:\n",
        "                return await self._generate_google_response(prompt, self.default_google_model, stream)\n",
        "            elif OLLAMA_AVAILABLE:\n",
        "                return await self._generate_ollama_response(prompt, self.default_ollama_model, stream)\n",
        "            else:\n",
        "                return await self._generate_fallback_response(prompt, stream)\n",
        "    \n",
        "    async def _generate_google_response(self, prompt: str, model_name: str, stream: bool = False) -> Tuple[Union[str, Generator], float]:\n",
        "        \"\"\"Generate a response using Google's models.\"\"\"\n",
        "        try:\n",
        "            # Log the request\n",
        "            request_id = int(time.time() * 1000)\n",
        "            log_data = {\n",
        "                \"request_id\": request_id,\n",
        "                \"model_type\": \"google\",\n",
        "                \"model\": model_name,\n",
        "                \"prompt_length\": len(prompt),\n",
        "                \"streaming\": stream\n",
        "            }\n",
        "            \n",
        "            # Write to log file\n",
        "            log_file = Path(box1_exports[\"LOGS_DIR\"]) / \"model_requests.jsonl\"\n",
        "            with open(log_file, \"a\") as f:\n",
        "                f.write(json.dumps(log_data) + \"\\n\")\n",
        "            \n",
        "            # Generate text\n",
        "            if stream:\n",
        "                response_stream = ai.generate_text(prompt, model_name=model_name, stream=True)\n",
        "                # For streaming, we return a fixed confidence\n",
        "                return response_stream, 0.9\n",
        "            else:\n",
        "                response = ai.generate_text(prompt, model_name=model_name)\n",
        "                # For non-streaming, we return a fixed confidence\n",
        "                return response, 0.9\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error generating text with Google model: {str(e)}\"\n",
        "            print(f\"‚ùå {error_msg}\")\n",
        "            return error_msg, 0.0\n",
        "    \n",
        "    async def _generate_ollama_response(self, prompt: str, model_name: str, stream: bool = False) -> Tuple[Union[str, Generator], float]:\n",
        "        \"\"\"Generate a response using Ollama.\"\"\"\n",
        "        try:\n",
        "            # Log the request\n",
        "            request_id = int(time.time() * 1000)\n",
        "            log_data = {\n",
        "                \"request_id\": request_id,\n",
        "                \"model_type\": \"ollama\",\n",
        "                \"model\": model_name,\n",
        "                \"prompt_length\": len(prompt),\n",
        "                \"streaming\": stream\n",
        "            }\n",
        "            \n",
        "            # Write to log file\n",
        "            log_file = Path(box1_exports[\"LOGS_DIR\"]) / \"model_requests.jsonl\"\n",
        "            with open(log_file, \"a\") as f:\n",
        "                f.write(json.dumps(log_data) + \"\\n\")\n",
        "            \n",
        "            # Prepare the request\n",
        "            payload = {\n",
        "                \"model\": model_name,\n",
        "                \"prompt\": prompt,\n",
        "                \"stream\": stream\n",
        "            }\n",
        "            \n",
        "            if stream:\n",
        "                # Streaming implementation\n",
        "                async def stream_response():\n",
        "                    response = requests.post(self.ollama_url, json=payload, stream=True)\n",
        "                    for line in response.iter_lines():\n",
        "                        if line:\n",
        "                            data = json.loads(line)\n",
        "                            yield data.get(\"response\", \"\")\n",
        "                \n",
        "                return stream_response(), 0.8\n",
        "            else:\n",
        "                # Non-streaming implementation\n",
        "                response = requests.post(self.ollama_url, json=payload)\n",
        "                response_json = response.json()\n",
        "                return response_json.get(\"response\", \"\"), 0.8\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error generating text with Ollama model: {str(e)}\"\n",
        "            print(f\"‚ùå {error_msg}\")\n",
        "            return error_msg, 0.0\n",
        "    \n",
        "    async def _generate_fallback_response(self, prompt: str, stream: bool = False) -> Tuple[Union[str, Generator], float]:\n",
        "        \"\"\"Generate a fallback response when no models are available.\"\"\"\n",
        "        if stream:\n",
        "            async def fallback_generator():\n",
        "                message = f\"[FALLBACK MODE] No AI models available. Would respond to: {prompt[:100]}...\"\n",
        "                for char in message:\n",
        "                    yield char\n",
        "                    await asyncio.sleep(0.01)\n",
        "            \n",
        "            return fallback_generator(), 0.0\n",
        "        else:\n",
        "            return f\"[FALLBACK MODE] No AI models available. Would respond to: {prompt[:100]}...\", 0.0\n",
        "    \n",
        "    def list_available_models(self):\n",
        "        \"\"\"List all available models.\"\"\"\n",
        "        models = []\n",
        "        \n",
        "        if GOOGLE_AI_AVAILABLE:\n",
        "            models.extend([{\"name\": model, \"type\": \"google\"} for model in google_models])\n",
        "        \n",
        "        if OLLAMA_AVAILABLE:\n",
        "            models.extend([{\"name\": model, \"type\": \"ollama\"} for model in ollama_models])\n",
        "        \n",
        "        return models\n",
        "\n",
        "# Initialize the model adapter\n",
        "model_adapter = ModelAdapter(\n",
        "    default_model_type=default_model_type,\n",
        "    default_google_model=default_model if default_model_type == \"google\" else None,\n",
        "    default_ollama_model=default_model if default_model_type == \"ollama\" else None\n",
        ")\n",
        "\n",
        "# Text generation function (wrapper around model adapter)\n",
        "async def generate_text(prompt: str, model_name: str = None, model_type: str = None, stream: bool = False) -> Union[str, Generator]:\n",
        "    \"\"\"Generate text using the model adapter.\"\"\"\n",
        "    response, confidence = await model_adapter.generate_response(\n",
        "        prompt=prompt,\n",
        "        model_type=model_type,\n",
        "        model_name=model_name,\n",
        "        stream=stream\n",
        "    )\n",
        "    return response\n",
        "\n",
        "# Memory system for conversation history\n",
        "class MemorySystem:\n",
        "    def __init__(self, max_history: int = 10):\n",
        "        self.max_history = max_history\n",
        "        self.conversations: Dict[str, List[Dict[str, str]]] = {}\n",
        "        self.current_conversation = \"default\"\n",
        "        self.conversations[self.current_conversation] = []\n",
        "    \n",
        "    def add_message(self, role: str, content: str, conversation_id: str = None) -> None:\n",
        "        \"\"\"Add a message to the conversation history.\"\"\"\n",
        "        conv_id = conversation_id or self.current_conversation\n",
        "        \n",
        "        if conv_id not in self.conversations:\n",
        "            self.conversations[conv_id] = []\n",
        "        \n",
        "        self.conversations[conv_id].append({\n",
        "            \"role\": role,\n",
        "            \"content\": content,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        })\n",
        "        \n",
        "        # Trim history if needed\n",
        "        if len(self.conversations[conv_id]) > self.max_history:\n",
        "            self.conversations[conv_id] = self.conversations[conv_id][-self.max_history:]\n",
        "    \n",
        "    def get_conversation(self, conversation_id: str = None) -> List[Dict[str, str]]:\n",
        "        \"\"\"Get the conversation history.\"\"\"\n",
        "        conv_id = conversation_id or self.current_conversation\n",
        "        return self.conversations.get(conv_id, [])\n",
        "    \n",
        "    def clear_conversation(self, conversation_id: str = None) -> None:\n",
        "        \"\"\"Clear the conversation history.\"\"\"\n",
        "        conv_id = conversation_id or self.current_conversation\n",
        "        if conv_id in self.conversations:\n",
        "            self.conversations[conv_id] = []\n",
        "    \n",
        "    def set_current_conversation(self, conversation_id: str) -> None:\n",
        "        \"\"\"Set the current conversation.\"\"\"\n",
        "        self.current_conversation = conversation_id\n",
        "        if conversation_id not in self.conversations:\n",
        "            self.conversations[conversation_id] = []\n",
        "    \n",
        "    def get_all_conversations(self) -> Dict[str, List[Dict[str, str]]]:\n",
        "        \"\"\"Get all conversations.\"\"\"\n",
        "        return self.conversations\n",
        "    \n",
        "    def save_to_file(self, file_path: str = None) -> str:\n",
        "        \"\"\"Save conversations to a file.\"\"\"\n",
        "        if not file_path:\n",
        "            file_path = Path(box1_exports[\"CONFIG_DIR\"]) / \"conversations.json\"\n",
        "        \n",
        "        with open(file_path, \"w\") as f:\n",
        "            json.dump(self.conversations, f, indent=2)\n",
        "        \n",
        "        return file_path\n",
        "    \n",
        "    def load_from_file(self, file_path: str = None) -> bool:\n",
        "        \"\"\"Load conversations from a file.\"\"\"\n",
        "        if not file_path:\n",
        "            file_path = Path(box1_exports[\"CONFIG_DIR\"]) / \"conversations.json\"\n",
        "        \n",
        "        if not os.path.exists(file_path):\n",
        "            return False\n",
        "        \n",
        "        try:\n",
        "            with open(file_path, \"r\") as f:\n",
        "                self.conversations = json.load(f)\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading conversations: {e}\")\n",
        "            return False\n",
        "\n",
        "# Initialize memory system\n",
        "memory = MemorySystem()\n",
        "memory_file = Path(box1_exports[\"CONFIG_DIR\"]) / \"conversations.json\"\n",
        "if memory_file.exists():\n",
        "    memory.load_from_file(str(memory_file))\n",
        "    print(f\"‚úÖ Loaded conversation history from {memory_file}\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è No existing conversation history found\")\n",
        "\n",
        "# Chat function that uses memory\n",
        "async def chat(message: str, conversation_id: str = None, model_name: str = None, \n",
        "              model_type: str = None, stream: bool = False) -> Union[str, Generator]:\n",
        "    \"\"\"Chat with the model using conversation history.\"\"\"\n",
        "    conv_id = conversation_id or memory.current_conversation\n",
        "    memory.add_message(\"user\", message, conv_id)\n",
        "    \n",
        "    # Build prompt with conversation history\n",
        "    conversation = memory.get_conversation(conv_id)\n",
        "    prompt = \"\\n\".join([f\"{msg['role']}: {msg['content']}\" for msg in conversation])\n",
        "    \n",
        "    # Generate response\n",
        "    response, confidence = await model_adapter.generate_response(\n",
        "        prompt=prompt,\n",
        "        model_type=model_type,\n",
        "        model_name=model_name,\n",
        "        stream=stream\n",
        "    )\n",
        "    \n",
        "    if not stream:\n",
        "        memory.add_message(\"assistant\", response, conv_id)\n",
        "    \n",
        "    return response, confidence\n",
        "\n",
        "# Test the model adapter\n",
        "print(\"\\nüß™ Testing model adapter with a simple query...\")\n",
        "test_response, test_confidence = await model_adapter.generate_response(\n",
        "    \"Hello, what can you do to help me with coding?\",\n",
        "    model_type=default_model_type,\n",
        "    model_name=default_model\n",
        ")\n",
        "print(f\"\\nModel response (confidence: {test_confidence:.2f}):\\n{test_response}\")\n",
        "\n",
        "# Export configuration for other boxes\n",
        "box2_exports = {\n",
        "    \"default_model\": default_model,\n",
        "    \"default_model_type\": default_model_type,\n",
        "    \"google_models\": google_models,\n",
        "    \"ollama_models\": ollama_models,\n",
        "    \"google_ai_available\": GOOGLE_AI_AVAILABLE,\n",
        "    \"ollama_available\": OLLAMA_AVAILABLE,\n",
        "    \"memory_initialized\": True\n",
        "}\n",
        "\n",
        "box2_exports_file = CONFIG_DIR / \"box2_exports.json\"\n",
        "with open(box2_exports_file, \"w\") as f:\n",
        "    json.dump(box2_exports, f, indent=2)\n",
        "\n",
        "print(\"\\nüéâ BOX 2 SETUP COMPLETED SUCCESSFULLY!\")\n",
        "print(f\"üß† Default Model Type: {default_model_type}\")\n",
        "print(f\"üß† Default Model: {default_model}\")\n",
        "print(f\"üî¢ Available Google Models: {len(google_models)}\")\n",
        "print(f\"üî¢ Available Ollama Models: {len(ollama_models)}\")\n",
        "print(f\"üíæ Memory System: Initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "box3-header"
      },
      "source": [
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "# ‚ïë üõ†Ô∏è BOX 3: Tool Registry and Execution Framework - v1.0                                                   ‚ïë\n",
        "# ‚ïë                                                                                                          ‚ïë\n",
        "# ‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CORE FEATURES ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n",
        "# ‚ïë - Tool registration system                                                                               ‚ïë\n",
        "# ‚ïë - Tool execution pipeline                                                                                ‚ïë\n",
        "# ‚ïë - File system operations                                                                                 ‚ïë\n",
        "# ‚ïë - Code execution tools                                                                                   ‚ïë\n",
        "# ‚ïë - Research and deployment tools                                                                          ‚ïë\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "box3-code"
      },
      "outputs": [],
      "source": [
        "print(\"üõ†Ô∏è BOX 3: Initializing Tool Registry and Execution Framework...\")\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import asyncio\n",
        "import subprocess\n",
        "import tempfile\n",
        "import inspect\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any, Optional, Union, Callable\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# Load configuration from previous boxes\n",
        "try:\n",
        "    with open(Path(\"./GoogleManusSystem/config/box1_exports.json\"), \"r\") as f:\n",
        "        box1_exports = json.load(f)\n",
        "    \n",
        "    with open(Path(\"./GoogleManusSystem/config/box2_exports.json\"), \"r\") as f:\n",
        "        box2_exports = json.load(f)\n",
        "    \n",
        "    # Extract paths and configuration\n",
        "    BASE_DIR = Path(box1_exports[\"BASE_DIR\"])\n",
        "    WORKSPACE_DIR = Path(box1_exports[\"WORKSPACE_DIR\"])\n",
        "    CONFIG_DIR = Path(box1_exports[\"CONFIG_DIR\"])\n",
        "    TOOLS_DIR = Path(box1_exports[\"TOOLS_DIR\"])\n",
        "    IS_COLAB = box1_exports[\"IS_COLAB\"]\n",
        "    \n",
        "    # Get model information\n",
        "    default_model = box2_exports[\"default_model\"]\n",
        "    default_model_type = box2_exports[\"default_model_type\"]\n",
        "    GOOGLE_AI_AVAILABLE = box2_exports[\"google_ai_available\"]\n",
        "    OLLAMA_AVAILABLE = box2_exports[\"ollama_available\"]\n",
        "    \n",
        "    print(\"‚úÖ Loaded configuration from previous boxes\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading previous box configurations: {e}\")\n",
        "    print(\"‚ö†Ô∏è Using default configuration\")\n",
        "    \n",
        "    # Default configuration if previous boxes haven't been run\n",
        "    BASE_DIR = Path(\"./GoogleManusSystem\")\n",
        "    WORKSPACE_DIR = BASE_DIR / \"workspace\"\n",
        "    CONFIG_DIR = BASE_DIR / \"config\"\n",
        "    TOOLS_DIR = BASE_DIR / \"tools\"\n",
        "    IS_COLAB = True\n",
        "    default_model = \"google/gemini-2.5-pro\"\n",
        "    default_model_type = \"google\"\n",
        "    GOOGLE_AI_AVAILABLE = False\n",
        "    OLLAMA_AVAILABLE = False\n",
        "\n",
        "# Ensure workspace directory exists\n",
        "WORKSPACE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "os.chdir(WORKSPACE_DIR)\n",
        "print(f\"üìÅ Working directory set to: {WORKSPACE_DIR}\")\n",
        "\n",
        "# Tool registry\n",
        "TOOL_REGISTRY: Dict[str, Callable] = {}\n",
        "\n",
        "# Tool registration decorator\n",
        "def register_tool(name: str):\n",
        "    \"\"\"Decorator to register a tool in the registry.\"\"\"\n",
        "    def decorator(func):\n",
        "        TOOL_REGISTRY[name] = func\n",
        "        return func\n",
        "    return decorator\n",
        "\n",
        "# Tool call model\n",
        "class ToolCall(BaseModel):\n",
        "    tool_name: str\n",
        "    tool_input: Dict[str, Any] = {}\n",
        "\n",
        "# Task request model\n",
        "class TaskRequest(BaseModel):\n",
        "    task: str\n",
        "    context: Optional[str] = None\n",
        "\n",
        "# Tool execution function\n",
        "async def call_tool(tool_call: ToolCall):\n",
        "    \"\"\"Execute a tool with the given input.\"\"\"\n",
        "    tool_name = tool_call.tool_name\n",
        "    tool_input = tool_call.tool_input\n",
        "    \n",
        "    if tool_name not in TOOL_REGISTRY:\n",
        "        return {\"error\": f\"Tool {tool_name} not found\"}\n",
        "    \n",
        "    try:\n",
        "        result = TOOL_REGISTRY[tool_name](**tool_input)\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return {\"error\": f\"Error executing tool {tool_name}: {str(e)}\"}\n",
        "\n",
        "# List available tools\n",
        "async def list_tools():\n",
        "    \"\"\"List all available tools with their descriptions and parameters.\"\"\"\n",
        "    tools_info = []\n",
        "    \n",
        "    for name, func in TOOL_REGISTRY.items():\n",
        "        # Get function signature and docstring\n",
        "        sig = inspect.signature(func)\n",
        "        doc = inspect.getdoc(func) or \"\"\n",
        "        \n",
        "        # Extract parameters\n",
        "        params = []\n",
        "        for param_name, param in sig.parameters.items():\n",
        "            param_info = {\n",
        "                \"name\": param_name,\n",
        "                \"required\": param.default == inspect.Parameter.empty,\n",
        "                \"type\": str(param.annotation) if param.annotation != inspect.Parameter.empty else \"Any\"\n",
        "            }\n",
        "            params.append(param_info)\n",
        "        \n",
        "        tools_info.append({\n",
        "            \"name\": name,\n",
        "            \"description\": doc.split(\"\\n\")[0] if doc else \"\",\n",
        "            \"parameters\": params\n",
        "        })\n",
        "    \n",
        "    return {\"tools\": tools_info}\n",
        "\n",
        "# ===== FILE SYSTEM TOOLS =====\n",
        "\n",
        "@register_tool(\"write_file\")\n",
        "def write_file(file_path: str, content: str):\n",
        "    \"\"\"Write content to a file.\"\"\"\n",
        "    try:\n",
        "        # Ensure the file path is within the workspace\n",
        "        full_path = WORKSPACE_DIR / file_path\n",
        "        \n",
        "        # Create parent directories if they don't exist\n",
        "        full_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        # Write the content\n",
        "        with open(full_path, \"w\") as f:\n",
        "            f.write(content)\n",
        "        \n",
        "        return {\"success\": True, \"message\": f\"File written to {file_path}\", \"path\": str(full_path)}\n",
        "    except Exception as e:\n",
        "        return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "@register_tool(\"read_file\")\n",
        "def read_file(file_path: str):\n",
        "    \"\"\"Read content from a file.\"\"\"\n",
        "    try:\n",
        "        # Ensure the file path is within the workspace\n",
        "        full_path = WORKSPACE_DIR / file_path\n",
        "        \n",
        "        # Check if the file exists\n",
        "        if not full_path.exists():\n",
        "            return {\"success\": False, \"error\": f\"File {file_path} not found\"}\n",
        "        \n",
        "        # Read the content\n",
        "        with open(full_path, \"r\") as f:\n",
        "            content = f.read()\n",
        "        \n",
        "        return {\"success\": True, \"content\": content, \"path\": str(full_path)}\n",
        "    except Exception as e:\n",
        "        return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "@register_tool(\"list_files\")\n",
        "def list_files(directory: str = \".\", pattern: str = \"*\"):\n",
        "    \"\"\"List files in a directory.\"\"\"\n",
        "    try:\n",
        "        # Ensure the directory path is within the workspace\n",
        "        full_path = WORKSPACE_DIR / directory\n",
        "        \n",
        "        # Check if the directory exists\n",
        "        if not full_path.exists():\n",
        "            return {\"success\": False, \"error\": f\"Directory {directory} not found\"}\n",
        "        \n",
        "        # List files\n",
        "        files = list(full_path.glob(pattern))\n",
        "        file_list = [{\n",
        "            \"name\": f.name,\n",
        "            \"path\": str(f.relative_to(WORKSPACE_DIR)),\n",
        "            \"type\": \"directory\" if f.is_dir() else \"file\",\n",
        "            \"size\": f.stat().st_size if f.is_file() else None\n",
        "        } for f in files]\n",
        "        \n",
        "        return {\"success\": True, \"files\": file_list, \"directory\": directory}\n",
        "    except Exception as e:\n",
        "        return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "@register_tool(\"search_files\")\n",
        "def search_files(pattern: str, content_pattern: str = None, directory: str = \".\"):\n",
        "    \"\"\"Search for files by name pattern and optionally by content.\"\"\"\n",
        "    try:\n",
        "        # Ensure the directory path is within the workspace\n",
        "        full_path = WORKSPACE_DIR / directory\n",
        "        \n",
        "        # Check if the directory exists\n",
        "        if not full_path.exists():\n",
        "            return {\"success\": False, \"error\": f\"Directory {directory} not found\"}\n",
        "        \n",
        "        # Find files matching the pattern\n",
        "        files = list(full_path.glob(f\"**/{pattern}\"))\n",
        "        \n",
        "        # If content pattern is provided, filter files by content\n",
        "        if content_pattern:\n",
        "            matching_files = []\n",
        "            for file in files:\n",
        "                if file.is_file():\n",
        "                    try:\n",
        "                        with open(file, \"r\") as f:\n",
        "                            content = f.read()\n",
        "                            if content_pattern in content:\n",
        "                                matching_files.append(file)\n",
        "                    except:\n",
        "                        # Skip files that can't be read as text\n",
        "                        pass\n",
        "            files = matching_files\n",
        "        \n",
        "        # Format results\n",
        "        file_list = [{\n",
        "            \"name\": f.name,\n",
        "            \"path\": str(f.relative_to(WORKSPACE_DIR)),\n",
        "            \"type\": \"directory\" if f.is_dir() else \"file\",\n",
        "            \"size\": f.stat().st_size if f.is_file() else None\n",
        "        } for f in files]\n",
        "        \n",
        "        return {\n",
        "            \"success\": True, \n",
        "            \"files\": file_list, \n",
        "            \"count\": len(file_list),\n",
        "            \"pattern\": pattern,\n",
        "            \"content_pattern\": content_pattern\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "# ===== CODE EXECUTION TOOLS =====\n",
        "\n",
        "@register_tool(\"execute_python\")\n",
        "def execute_python(code: str, timeout: int = 30):\n",
        "    \"\"\"Execute Python code and return the result.\"\"\"\n",
        "    try:\n",
        "        # Create a temporary file\n",
        "        with tempfile.NamedTemporaryFile(suffix=\".py\", delete=False) as temp_file:\n",
        "            temp_file.write(code.encode())\n",
        "            temp_path = temp_file.name\n",
        "        \n",
        "        # Execute the code\n",
        "        result = subprocess.run(\n",
        "            [sys.executable, temp_path],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=timeout\n",
        "        )\n",
        "        \n",
        "        # Clean up\n",
        "        os.unlink(temp_path)\n",
        "        \n",
        "        return {\n",
        "            \"success\": result.returncode == 0,\n",
        "            \"stdout\": result.stdout,\n",
        "            \"stderr\": result.stderr,\n",
        "            \"exit_code\": result.returncode\n",
        "        }\n",
        "    except subprocess.TimeoutExpired:\n",
        "        return {\"success\": False, \"error\": f\"Execution timed out after {timeout} seconds\"}\n",
        "    except Exception as e:\n",
        "        return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "@register_tool(\"review_code\")\n",
        "def review_code(code: str, language: str = \"python\"):\n",
        "    \"\"\"Review code and provide suggestions for improvement.\"\"\"\n",
        "    try:\n",
        "        # Import the model adapter from Box 2\n",
        "        from __main__ import model_adapter\n",
        "        \n",
        "        # Prepare the prompt\n",
        "        prompt = f\"\"\"Review the following {language} code and provide suggestions for improvement:\n",
        "\n",
        "```{language}\n",
        "{code}\n",
        "```\n",
        "\n",
        "Please analyze the code for:\n",
        "1. Bugs and logical errors\n",
        "2. Performance issues\n",
        "3. Style and best practices\n",
        "4. Security concerns\n",
        "5. Potential improvements\n",
        "\n",
        "For each issue, provide:\n",
        "- A description of the issue\n",
        "- The problematic code snippet\n",
        "- A suggested fix\n",
        "\n",
        "Finally, provide an overall assessment and a score from 1-10.\"\"\"\n",
        "        \n",
        "        # Generate the review\n",
        "        loop = asyncio.get_event_loop()\n",
        "        review, confidence = loop.run_until_complete(\n",
        "            model_adapter.generate_response(prompt)\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"review\": review,\n",
        "            \"language\": language,\n",
        "            \"confidence\": confidence\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "@register_tool(\"generate_tests\")\n",
        "def generate_tests(code: str, language: str = \"python\"):\n",
        "    \"\"\"Generate unit tests for the given code.\"\"\"\n",
        "    try:\n",
        "        # Import the model adapter from Box 2\n",
        "        from __main__ import model_adapter\n",
        "        \n",
        "        # Prepare the prompt\n",
        "        prompt = f\"\"\"Generate comprehensive unit tests for the following {language} code:\n",
        "\n",
        "```{language}\n",
        "{code}\n",
        "```\n",
        "\n",
        "Please create tests that:\n",
        "1. Cover all functions and methods\n",
        "2. Test edge cases and error conditions\n",
        "3. Achieve high code coverage\n",
        "4. Follow best practices for {language} testing\n",
        "\n",
        "Return only the test code without explanations.\"\"\"\n",
        "        \n",
        "        # Generate the tests\n",
        "        loop = asyncio.get_event_loop()\n",
        "        tests, confidence = loop.run_until_complete(\n",
        "            model_adapter.generate_response(prompt)\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"tests\": tests,\n",
        "            \"language\": language,\n",
        "            \"confidence\": confidence\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "@register_tool(\"install_package\")\n",
        "def install_package(package_name: str):\n",
        "    \"\"\"Install a Python package.\"\"\"\n",
        "    try:\n",
        "        # Execute pip install\n",
        "        result = subprocess.run(\n",
        "            [sys.executable, \"-m\", \"pip\", \"install\", package_name],\n",
        "            capture_output=True,\n",
        "            text=True\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            \"success\": result.returncode == 0,\n",
        "            \"stdout\": result.stdout,\n",
        "            \"stderr\": result.stderr,\n",
        "            \"exit_code\": result.returncode\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "# ===== RESEARCH TOOLS =====\n",
        "\n",
        "@register_tool(\"search_web\")\n",
        "def search_web(query: str, num_results: int = 5):\n",
        "    \"\"\"Search the web for information (simulated in this version).\"\"\"\n",
        "    # In a real implementation, this would use a search API\n",
        "    # For now, we'll just return a message\n",
        "    return {\n",
        "        \"success\": True,\n",
        "        \"message\": f\"Would search for: {query} (limited to {num_results} results)\",\n",
        "        \"results\": []\n",
        "    }\n",
        "\n",
        "@register_tool(\"summarize_text\")\n",
        "def summarize_text(text: str, max_length: int = 200):\n",
        "    \"\"\"Summarize a long text.\"\"\"\n",
        "    try:\n",
        "        # Import the model adapter from Box 2\n",
        "        from __main__ import model_adapter\n",
        "        \n",
        "        # Prepare the prompt\n",
        "        prompt = f\"\"\"Summarize the following text in {max_length} words or less:\n",
        "\n",
        "{text}\n",
        "\n",
        "Summary:\"\"\"\n",
        "        \n",
        "        # Generate the summary\n",
        "        loop = asyncio.get_event_loop()\n",
        "        summary, confidence = loop.run_until_complete(\n",
        "            model_adapter.generate_response(prompt)\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"summary\": summary,\n",
        "            \"original_length\": len(text),\n",
        "            \"summary_length\": len(summary),\n",
        "            \"confidence\": confidence\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "# ===== DEPLOYMENT TOOLS =====\n",
        "\n",
        "@register_tool(\"launch_site\")\n",
        "def launch_site(site_path: str, port: int = 8000):\n",
        "    \"\"\"Launch a website locally.\"\"\"\n",
        "    try:\n",
        "        # Ensure the site path is within the workspace\n",
        "        full_path = WORKSPACE_DIR / site_path\n",
        "        \n",
        "        # Create the directory if it doesn't exist\n",
        "        full_path.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        # Create a simple index.html if it doesn't exist\n",
        "        index_path = full_path / \"index.html\"\n",
        "        if not index_path.exists():\n",
        "            with open(index_path, \"w\") as f:\n",
        "                f.write(f\"\"\"\n",
        "                <!DOCTYPE html>\n",
        "                <html>\n",
        "                <head>\n",
        "                    <title>Google Manus Site</title>\n",
        "                    <style>\n",
        "                        body {{ font-family: Arial, sans-serif; margin: 40px; }}\n",
        "                        h1 {{ color: #4285F4; }}\n",
        "                    </style>\n",
        "                </head>\n",
        "                <body>\n",
        "                    <h1>Welcome to Google Manus Site</h1>\n",
        "                    <p>This is a simple website launched by Google Manus System.</p>\n",
        "                    <p>Current time: {time.strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
        "                </body>\n",
        "                </html>\"\"\")\n",
        "        \n",
        "        # Create a simple server script\n",
        "        server_path = full_path / \"server.py\"\n",
        "        with open(server_path, \"w\") as f:\n",
        "            f.write(f\"\"\"\n",
        "import http.server\n",
        "import socketserver\n",
        "import os\n",
        "\n",
        "PORT = {port}\n",
        "DIRECTORY = '{full_path}'\n",
        "\n",
        "class Handler(http.server.SimpleHTTPRequestHandler):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, directory=DIRECTORY, **kwargs)\n",
        "    \n",
        "    def end_headers(self):\n",
        "        self.send_header('Access-Control-Allow-Origin', '*')\n",
        "        super().end_headers()\n",
        "\n",
        "with socketserver.TCPServer((\"\", PORT), Handler) as httpd:\n",
        "    print(f\"Serving at port {{PORT}}\")\n",
        "    httpd.serve_forever()\n",
        "            \"\"\")\n",
        "        \n",
        "        # Start the server in the background\n",
        "        process = subprocess.Popen([sys.executable, str(server_path)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        \n",
        "        # Wait a moment for the server to start\n",
        "        time.sleep(2)\n",
        "        \n",
        "        # Check if the process is still running\n",
        "        if process.poll() is not None:\n",
        "            stdout, stderr = process.communicate()\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"error\": f\"Server failed to start: {stderr.decode()}\"\n",
        "            }\n",
        "        \n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"message\": f\"Site launched at http://localhost:{port}\",\n",
        "            \"url\": f\"http://localhost:{port}\",\n",
        "            \"site_path\": str(full_path),\n",
        "            \"process_id\": process.pid\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "@register_tool(\"setup_frp\")\n",
        "def setup_frp(local_port: int = 8000, custom_domain: str = None):\n",
        "    \"\"\"Setup FRP tunnel for public access.\"\"\"\n",
        "    try:\n",
        "        # Download FRP if not exists\n",
        "        frp_dir = BASE_DIR / \"frp\"\n",
        "        if not frp_dir.exists():\n",
        "            print(\"‚è≥ Downloading FRP...\")\n",
        "            os.makedirs(frp_dir, exist_ok=True)\n",
        "            subprocess.run([\"wget\", \"https://github.com/fatedier/frp/releases/download/v0.51.3/frp_0.51.3_linux_amd64.tar.gz\", \"-O\", str(frp_dir / \"frp.tar.gz\")])\n",
        "            subprocess.run([\"tar\", \"-xzf\", str(frp_dir / \"frp.tar.gz\"), \"-C\", str(frp_dir), \"--strip-components=1\"])\n",
        "            os.remove(str(frp_dir / \"frp.tar.gz\"))\n",
        "            print(\"‚úÖ FRP downloaded and extracted\")\n",
        "        \n",
        "        # Create FRP config\n",
        "        domain = custom_domain or f\"manus-{int(time.time())}.example.com\"\n",
        "        frp_config = f\"\"\"\n",
        "[common]\n",
        "server_addr = frp.example.com\n",
        "server_port = 7000\n",
        "token = your_token_here\n",
        "\n",
        "[web]\n",
        "type = http\n",
        "local_port = {local_port}\n",
        "custom_domains = {domain}\n",
        "        \"\"\"\n",
        "        \n",
        "        with open(frp_dir / \"frpc.ini\", \"w\") as f:\n",
        "            f.write(frp_config)\n",
        "        \n",
        "        # In a real implementation, we would start FRP here\n",
        "        # For now, we'll just return the configuration\n",
        "        \n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"message\": \"FRP configuration created\",\n",
        "            \"config_path\": str(frp_dir / \"frpc.ini\"),\n",
        "            \"domain\": domain,\n",
        "            \"local_port\": local_port,\n",
        "            \"url\": f\"http://{domain}\"\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "# ===== AGENT TOOLS =====\n",
        "\n",
        "@register_tool(\"action_agent\")\n",
        "def action_agent(task: str, context: str = None):\n",
        "    \"\"\"Execute a task using the agent.\"\"\"\n",
        "    try:\n",
        "        # Import the model adapter from Box 2\n",
        "        from __main__ import model_adapter\n",
        "        \n",
        "        # Prepare the prompt\n",
        "        prompt = f\"Task: {task}\\n\"\n",
        "        if context:\n",
        "            prompt += f\"Context: {context}\\n\"\n",
        "        \n",
        "        prompt += \"\\nPlease help me complete this task. Provide a step-by-step approach and any code or commands needed.\"\n",
        "        \n",
        "        # Generate the response\n",
        "        loop = asyncio.get_event_loop()\n",
        "        response, confidence = loop.run_until_complete(\n",
        "            model_adapter.generate_response(prompt)\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"task\": task,\n",
        "            \"response\": response,\n",
        "            \"confidence\": confidence\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "@register_tool(\"get_agent_memory\")\n",
        "def get_agent_memory():\n",
        "    \"\"\"Get the agent's memory.\"\"\"\n",
        "    try:\n",
        "        # Import the memory system from Box 2\n",
        "        from __main__ import memory\n",
        "        \n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"conversations\": memory.get_all_conversations()\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "@register_tool(\"clear_agent_memory\")\n",
        "def clear_agent_memory(conversation_id: str = None):\n",
        "    \"\"\"Clear the agent's memory.\"\"\"\n",
        "    try:\n",
        "        # Import the memory system from Box 2\n",
        "        from __main__ import memory\n",
        "        \n",
        "        memory.clear_conversation(conversation_id)\n",
        "        \n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"message\": f\"Memory cleared for conversation {conversation_id or 'default'}\"\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "# Print registered tools\n",
        "print(f\"‚úÖ Registered {len(TOOL_REGISTRY)} tools\")\n",
        "for tool_name in TOOL_REGISTRY.keys():\n",
        "    print(f\"  - {tool_name}\")\n",
        "\n",
        "# Export configuration for other boxes\n",
        "box3_exports = {\n",
        "    \"tools_registered\": list(TOOL_REGISTRY.keys()),\n",
        "    \"workspace_dir\": str(WORKSPACE_DIR)\n",
        "}\n",
        "\n",
        "box3_exports_file = CONFIG_DIR / \"box3_exports.json\"\n",
        "with open(box3_exports_file, \"w\") as f:\n",
        "    json.dump(box3_exports, f, indent=2)\n",
        "\n",
        "print(\"\\nüéâ BOX 3 SETUP COMPLETED SUCCESSFULLY!\")\n",
        "print(f\"üõ†Ô∏è Tools Registered: {len(TOOL_REGISTRY)}\")\n",
        "print(f\"üìÅ Workspace Directory: {WORKSPACE_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "box4-header"
      },
      "source": [
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "# ‚ïë üñ•Ô∏è BOX 4: User Interface and Interaction - v1.0                                                          ‚ïë\n",
        "# ‚ïë                                                                                                          ‚ïë\n",
        "# ‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CORE FEATURES ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n",
        "# ‚ïë - Jupyter widgets interface                                                                              ‚ïë\n",
        "# ‚ïë - Chat interface                                                                                         ‚ïë\n",
        "# ‚ïë - Task execution interface                                                                               ‚ïë\n",
        "# ‚ïë - Tool execution interface                                                                               ‚ïë\n",
        "# ‚ïë - Code editor interface                                                                                  ‚ïë\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "box4-code"
      },
      "outputs": [],
      "source": [
        "print(\"üñ•Ô∏è BOX 4: Initializing User Interface and Interaction...\")\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import asyncio\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any, Optional, Union, Callable\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "# Load configuration from previous boxes\n",
        "try:\n",
        "    with open(Path(\"./GoogleManusSystem/config/box1_exports.json\"), \"r\") as f:\n",
        "        box1_exports = json.load(f)\n",
        "    \n",
        "    with open(Path(\"./GoogleManusSystem/config/box2_exports.json\"), \"r\") as f:\n",
        "        box2_exports = json.load(f)\n",
        "    \n",
        "    with open(Path(\"./GoogleManusSystem/config/box3_exports.json\"), \"r\") as f:\n",
        "        box3_exports = json.load(f)\n",
        "    \n",
        "    # Extract configuration\n",
        "    WORKSPACE_DIR = Path(box1_exports[\"WORKSPACE_DIR\"])\n",
        "    IS_COLAB = box1_exports[\"IS_COLAB\"]\n",
        "    config = box1_exports[\"config\"]\n",
        "    \n",
        "    default_model = box2_exports[\"default_model\"]\n",
        "    default_model_type = box2_exports[\"default_model_type\"]\n",
        "    google_models = box2_exports[\"google_models\"]\n",
        "    ollama_models = box2_exports[\"ollama_models\"]\n",
        "    GOOGLE_AI_AVAILABLE = box2_exports[\"google_ai_available\"]\n",
        "    OLLAMA_AVAILABLE = box2_exports[\"ollama_available\"]\n",
        "    \n",
        "    tools_registered = box3_exports[\"tools_registered\"]\n",
        "    \n",
        "    print(\"‚úÖ Loaded configuration from previous boxes\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading previous box configurations: {e}\")\n",
        "    print(\"‚ö†Ô∏è Using default configuration\")\n",
        "    \n",
        "    # Default configuration if previous boxes haven't been run\n",
        "    WORKSPACE_DIR = Path(\"./GoogleManusSystem/workspace\")\n",
        "    IS_COLAB = True\n",
        "    config = {\"human_review_enabled\": True, \"auto_approve_threshold\": 0.8}\n",
        "    \n",
        "    default_model = \"google/gemini-2.5-pro\"\n",
        "    default_model_type = \"google\"\n",
        "    google_models = [\"google/gemini-2.5-pro\"]\n",
        "    ollama_models = [\"llama3\"]\n",
        "    GOOGLE_AI_AVAILABLE = False\n",
        "    OLLAMA_AVAILABLE = False\n",
        "    \n",
        "    tools_registered = [\"write_file\", \"read_file\", \"list_files\", \"execute_python\", \"action_agent\"]\n",
        "\n",
        "# Import functions from previous boxes\n",
        "try:\n",
        "    from __main__ import generate_text, chat, memory, call_tool, TOOL_REGISTRY, model_adapter\n",
        "    print(\"‚úÖ Imported functions from previous boxes\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Error importing functions: {e}\")\n",
        "    print(\"‚ö†Ô∏è UI will have limited functionality\")\n",
        "    \n",
        "    # Define placeholder functions\n",
        "    async def generate_text(prompt, model_name=None, model_type=None, stream=False):\n",
        "        return f\"[PLACEHOLDER] Would generate text for: {prompt[:50]}...\"\n",
        "    \n",
        "    async def chat(message, conversation_id=None, model_name=None, model_type=None, stream=False):\n",
        "        return f\"[PLACEHOLDER] Would chat about: {message[:50]}...\", 0.5\n",
        "    \n",
        "    class MemorySystem:\n",
        "        def get_conversation(self, conversation_id=None):\n",
        "            return []\n",
        "        \n",
        "        def add_message(self, role, content, conversation_id=None):\n",
        "            pass\n",
        "        \n",
        "        def clear_conversation(self, conversation_id=None):\n",
        "            pass\n",
        "    \n",
        "    memory = MemorySystem()\n",
        "    \n",
        "    class ToolCall:\n",
        "        def __init__(self, tool_name, tool_input):\n",
        "            self.tool_name = tool_name\n",
        "            self.tool_input = tool_input\n",
        "    \n",
        "    async def call_tool(tool_call):\n",
        "        return {\"error\": \"Tool execution not available\"}\n",
        "    \n",
        "    TOOL_REGISTRY = {}\n",
        "    for tool in tools_registered:\n",
        "        TOOL_REGISTRY[tool] = lambda **kwargs: {\"error\": \"Tool not implemented\"}\n",
        "    \n",
        "    class ModelAdapter:\n",
        "        def __init__(self):\n",
        "            pass\n",
        "        \n",
        "        async def generate_response(self, prompt, model_type=None, model_name=None, stream=False):\n",
        "            return f\"[PLACEHOLDER] Would generate response for: {prompt[:50]}...\", 0.5\n",
        "        \n",
        "        def list_available_models(self):\n",
        "            return []\n",
        "    \n",
        "    model_adapter = ModelAdapter()\n",
        "\n",
        "# ===== HELPER FUNCTIONS =====\n",
        "\n",
        "def format_code(code, language=\"python\"):\n",
        "    \"\"\"Format code with syntax highlighting.\"\"\"\n",
        "    return f\"\"\"<div style=\"background-color: #f5f5f5; padding: 10px; border-radius: 5px; margin: 10px 0;\">\n",
        "    <pre><code class=\"{language}\">{code}</code></pre>\n",
        "    </div>\"\"\"\n",
        "\n",
        "def format_message(role, content):\n",
        "    \"\"\"Format a chat message.\"\"\"\n",
        "    if role == \"user\":\n",
        "        color = \"#e6f7ff\"\n",
        "        icon = \"üë§\"\n",
        "    else:\n",
        "        color = \"#f0f0f0\"\n",
        "        icon = \"ü§ñ\"\n",
        "    \n",
        "    return f\"\"\"<div style=\"background-color: {color}; padding: 10px; border-radius: 5px; margin: 10px 0;\">\n",
        "    <strong>{icon} {role.capitalize()}</strong>\n",
        "    <div style=\"margin-top: 5px;\">{content}</div>\n",
        "    </div>\"\"\"\n",
        "\n",
        "def format_tool_result(result):\n",
        "    \"\"\"Format a tool execution result.\"\"\"\n",
        "    if isinstance(result, dict) and \"error\" in result:\n",
        "        return f\"\"\"<div style=\"background-color: #ffe6e6; padding: 10px; border-radius: 5px; margin: 10px 0;\">\n",
        "        <strong>‚ùå Error</strong>\n",
        "        <div style=\"margin-top: 5px;\">{result['error']}</div>\n",
        "        </div>\"\"\"\n",
        "    \n",
        "    if isinstance(result, dict) and \"success\" in result and not result[\"success\"]:\n",
        "        return f\"\"\"<div style=\"background-color: #ffe6e6; padding: 10px; border-radius: 5px; margin: 10px 0;\">\n",
        "        <strong>‚ùå Error</strong>\n",
        "        <div style=\"margin-top: 5px;\">{result.get('error', 'Unknown error')}</div>\n",
        "        </div>\"\"\"\n",
        "    \n",
        "    # Format success result\n",
        "    result_html = \"<div style=\\\"background-color: #e6ffe6; padding: 10px; border-radius: 5px; margin: 10px 0;\\\">\\n\"\n",
        "    result_html += \"<strong>‚úÖ Success</strong>\\n\"\n",
        "    result_html += \"<div style=\\\"margin-top: 5px;\\\">\\n\"\n",
        "    \n",
        "    if isinstance(result, dict):\n",
        "        for key, value in result.items():\n",
        "            if key in [\"success\", \"error\"]:\n",
        "                continue\n",
        "            \n",
        "            if key == \"stdout\" and value:\n",
        "                result_html += f\"<strong>Output:</strong>\\n\"\n",
        "                result_html += f\"<pre>{value}</pre>\\n\"\n",
        "            elif key == \"stderr\" and value:\n",
        "                result_html += f\"<strong>Errors:</strong>\\n\"\n",
        "                result_html += f\"<pre>{value}</pre>\\n\"\n",
        "            elif key == \"content\" and value:\n",
        "                result_html += f\"<strong>Content:</strong>\\n\"\n",
        "                result_html += f\"<pre>{value}</pre>\\n\"\n",
        "            elif key == \"files\" and value:\n",
        "                result_html += f\"<strong>Files:</strong>\\n\"\n",
        "                result_html += \"<ul>\\n\"\n",
        "                for file in value:\n",
        "                    result_html += f\"<li>{file['name']} ({file['type']})</li>\\n\"\n",
        "                result_html += \"</ul>\\n\"\n",
        "            elif key == \"message\" and value:\n",
        "                result_html += f\"<strong>Message:</strong> {value}\\n\"\n",
        "            elif key == \"url\" and value:\n",
        "                result_html += f\"<strong>URL:</strong> <a href=\\\"{value}\\\" target=\\\"_blank\\\">{value}</a>\\n\"\n",
        "            elif key == \"response\" and value:\n",
        "                result_html += f\"<strong>Response:</strong>\\n\"\n",
        "                result_html += f\"<div>{value}</div>\\n\"\n",
        "            elif key == \"review\" and value:\n",
        "                result_html += f\"<strong>Review:</strong>\\n\"\n",
        "                result_html += f\"<div>{value}</div>\\n\"\n",
        "            elif key == \"tests\" and value:\n",
        "                result_html += f\"<strong>Tests:</strong>\\n\"\n",
        "                result_html += f\"<pre>{value}</pre>\\n\"\n",
        "            elif key == \"summary\" and value:\n",
        "                result_html += f\"<strong>Summary:</strong>\\n\"\n",
        "                result_html += f\"<div>{value}</div>\\n\"\n",
        "    else:\n",
        "        result_html += f\"<pre>{result}</pre>\\n\"\n",
        "    \n",
        "    result_html += \"</div>\\n</div>\"\n",
        "    \n",
        "    return result_html\n",
        "\n",
        "# ===== UI COMPONENTS =====\n",
        "\n",
        "# Header\n",
        "header = widgets.HTML(\n",
        "    value=\"<h1>ü§ñ Google Manus System</h1>\"\n",
        ")\n",
        "\n",
        "# Model selection\n",
        "model_type_dropdown = widgets.Dropdown(\n",
        "    options=[\n",
        "        (\"Google\", \"google\") if GOOGLE_AI_AVAILABLE else None,\n",
        "        (\"Ollama\", \"ollama\") if OLLAMA_AVAILABLE else None,\n",
        "        (\"Fallback\", \"fallback\") if not GOOGLE_AI_AVAILABLE and not OLLAMA_AVAILABLE else None\n",
        "    ],\n",
        "    value=default_model_type,\n",
        "    description='Model Type:',\n",
        "    disabled=not (GOOGLE_AI_AVAILABLE or OLLAMA_AVAILABLE),\n",
        "    style={'description_width': '100px'}\n",
        ")\n",
        "\n",
        "# Filter out None values\n",
        "model_type_dropdown.options = [opt for opt in model_type_dropdown.options if opt is not None]\n",
        "\n",
        "# Google model selection\n",
        "google_model_dropdown = widgets.Dropdown(\n",
        "    options=google_models,\n",
        "    value=default_model if default_model_type == \"google\" else (google_models[0] if google_models else None),\n",
        "    description='Google Model:',\n",
        "    disabled=not GOOGLE_AI_AVAILABLE or default_model_type != \"google\",\n",
        "    style={'description_width': '100px'}\n",
        ")\n",
        "\n",
        "# Ollama model selection\n",
        "ollama_model_dropdown = widgets.Dropdown(\n",
        "    options=ollama_models,\n",
        "    value=default_model if default_model_type == \"ollama\" else (ollama_models[0] if ollama_models else None),\n",
        "    description='Ollama Model:',\n",
        "    disabled=not OLLAMA_AVAILABLE or default_model_type != \"ollama\",\n",
        "    style={'description_width': '100px'}\n",
        ")\n",
        "\n",
        "# Human review toggle\n",
        "human_review_toggle = widgets.Checkbox(\n",
        "    value=config.get(\"human_review_enabled\", True),\n",
        "    description='Enable Human Review',\n",
        "    disabled=False,\n",
        "    indent=False\n",
        ")\n",
        "\n",
        "# Tabs for different interfaces\n",
        "tab = widgets.Tab()\n",
        "tab_contents = []\n",
        "\n",
        "# ===== CHAT INTERFACE =====\n",
        "\n",
        "chat_output = widgets.Output()\n",
        "chat_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Type a message...',\n",
        "    description='',\n",
        "    disabled=False\n",
        ")\n",
        "chat_button = widgets.Button(\n",
        "    description='Send',\n",
        "    disabled=False,\n",
        "    button_style='primary',\n",
        "    tooltip='Send message',\n",
        "    icon='paper-plane'\n",
        ")\n",
        "clear_chat_button = widgets.Button(\n",
        "    description='Clear Chat',\n",
        "    disabled=False,\n",
        "    button_style='danger',\n",
        "    tooltip='Clear chat history',\n",
        "    icon='trash'\n",
        ")\n",
        "\n",
        "chat_controls = widgets.HBox([chat_input, chat_button, clear_chat_button])\n",
        "chat_interface = widgets.VBox([chat_output, chat_controls])\n",
        "\n",
        "# Chat event handlers\n",
        "async def on_chat_button_clicked(b):\n",
        "    message = chat_input.value\n",
        "    if not message.strip():\n",
        "        return\n",
        "    \n",
        "    chat_input.value = ''\n",
        "    \n",
        "    with chat_output:\n",
        "        display(HTML(format_message(\"user\", message)))\n",
        "        \n",
        "        # Add to memory\n",
        "        memory.add_message(\"user\", message)\n",
        "        \n",
        "        # Get the selected model\n",
        "        model_type = model_type_dropdown.value\n",
        "        model_name = None\n",
        "        if model_type == \"google\":\n",
        "            model_name = google_model_dropdown.value\n",
        "        elif model_type == \"ollama\":\n",
        "            model_name = ollama_model_dropdown.value\n",
        "        \n",
        "        # Generate response\n",
        "        display(HTML(\"<p><em>Generating response...</em></p>\"))\n",
        "        response, confidence = await chat(message, model_name=model_name, model_type=model_type)\n",
        "        \n",
        "        # Check if human review is needed\n",
        "        if human_review_toggle.value and confidence < config.get(\"auto_approve_threshold\", 0.8):\n",
        "            display(HTML(f\"\"\"<div style=\"background-color: #fff3cd; padding: 10px; border-radius: 5px; margin: 10px 0;\">\n",
        "            <strong>‚ö†Ô∏è Response pending human review (confidence: {confidence:.2f})</strong>\n",
        "            <div style=\"margin-top: 5px;\">The response will be displayed after human review.</div>\n",
        "            </div>\"\"\"))\n",
        "            \n",
        "            # In a real implementation, this would queue the response for human review\n",
        "            # For now, we'll just display it after a delay\n",
        "            await asyncio.sleep(2)\n",
        "            display(HTML(\"<p><em>Human review completed.</em></p>\"))\n",
        "        \n",
        "        # Add to memory\n",
        "        memory.add_message(\"assistant\", response)\n",
        "        \n",
        "        # Display response\n",
        "        display(HTML(format_message(\"assistant\", response)))\n",
        "\n",
        "def on_chat_input_submitted(sender):\n",
        "    asyncio.create_task(on_chat_button_clicked(None))\n",
        "\n",
        "def on_clear_chat_button_clicked(b):\n",
        "    memory.clear_conversation()\n",
        "    with chat_output:\n",
        "        clear_output()\n",
        "        display(HTML(\"<p>Chat history cleared.</p>\"))\n",
        "\n",
        "chat_button.on_click(lambda b: asyncio.create_task(on_chat_button_clicked(b)))\n",
        "chat_input.on_submit(on_chat_input_submitted)\n",
        "clear_chat_button.on_click(on_clear_chat_button_clicked)\n",
        "\n",
        "# ===== TASK EXECUTION INTERFACE =====\n",
        "\n",
        "task_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Enter a task...',\n",
        "    description='Task:',\n",
        "    disabled=False,\n",
        "    style={'description_width': '100px'}\n",
        ")\n",
        "task_context = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='Optional context...',\n",
        "    description='Context:',\n",
        "    disabled=False,\n",
        "    style={'description_width': '100px'}\n",
        ")\n",
        "task_button = widgets.Button(\n",
        "    description='Execute Task',\n",
        "    disabled=False,\n",
        "    button_style='success',\n",
        "    tooltip='Execute the task',\n",
        "    icon='play'\n",
        ")\n",
        "task_output = widgets.Output()\n",
        "\n",
        "task_interface = widgets.VBox([task_input, task_context, task_button, task_output])\n",
        "\n",
        "# Task event handlers\n",
        "def on_task_button_clicked(b):\n",
        "    task = task_input.value\n",
        "    context = task_context.value\n",
        "    \n",
        "    if not task.strip():\n",
        "        return\n",
        "    \n",
        "    with task_output:\n",
        "        clear_output()\n",
        "        display(HTML(f\"<p><strong>Task:</strong> {task}</p>\"))\n",
        "        if context:\n",
        "            display(HTML(f\"<p><strong>Context:</strong> {context}</p>\"))\n",
        "        \n",
        "        display(HTML(\"<p><em>Executing task...</em></p>\"))\n",
        "        \n",
        "        # Call the action_agent tool\n",
        "        if \"action_agent\" in TOOL_REGISTRY:\n",
        "            result = TOOL_REGISTRY[\"action_agent\"](task=task, context=context)\n",
        "            display(HTML(format_tool_result(result)))\n",
        "        else:\n",
        "            display(HTML(\"<p>‚ùå Action agent tool not available.</p>\"))\n",
        "\n",
        "task_button.on_click(on_task_button_clicked)\n",
        "\n",
        "# ===== TOOL EXECUTION INTERFACE =====\n",
        "\n",
        "tool_dropdown = widgets.Dropdown(\n",
        "    options=tools_registered,\n",
        "    value=tools_registered[0] if tools_registered else None,\n",
        "    description='Tool:',\n",
        "    disabled=not tools_registered,\n",
        "    style={'description_width': '100px'}\n",
        ")\n",
        "tool_input = widgets.Textarea(\n",
        "    value='{}',\n",
        "    placeholder='Enter tool input as JSON...',\n",
        "    description='Input:',\n",
        "    disabled=False,\n",
        "    style={'description_width': '100px'}\n",
        ")\n",
        "tool_button = widgets.Button(\n",
        "    description='Execute Tool',\n",
        "    disabled=False,\n",
        "    button_style='info',\n",
        "    tooltip='Execute the selected tool',\n",
        "    icon='wrench'\n",
        ")\n",
        "tool_output = widgets.Output()\n",
        "\n",
        "tool_interface = widgets.VBox([tool_dropdown, tool_input, tool_button, tool_output])\n",
        "\n",
        "# Tool event handlers\n",
        "def on_tool_dropdown_change(change):\n",
        "    tool_name = change['new']\n",
        "    if tool_name == \"write_file\":\n",
        "        tool_input.value = '{\"file_path\": \"example.txt\", \"content\": \"Hello, world!\"}'\n",
        "    elif tool_name == \"read_file\":\n",
        "        tool_input.value = '{\"file_path\": \"example.txt\"}'\n",
        "    elif tool_name == \"list_files\":\n",
        "        tool_input.value = '{\"directory\": \".\", \"pattern\": \"*\"}'\n",
        "    elif tool_name == \"search_files\":\n",
        "        tool_input.value = '{\"pattern\": \"*.py\", \"content_pattern\": \"import\", \"directory\": \".\"}'\n",
        "    elif tool_name == \"execute_python\":\n",
        "        tool_input.value = '{\"code\": \"print(\\\\'Hello, world!\\\\')\\\\nfor i in range(5):\\\\n    print(i)\"}'\n",
        "    elif tool_name == \"review_code\":\n",
        "        tool_input.value = '{\"code\": \"def fibonacci(n):\\\\n    if n <= 0:\\\\n        return 0\\\\n    elif n == 1:\\\\n        return 1\\\\n    else:\\\\n        return fibonacci(n-1) + fibonacci(n-2)\", \"language\": \"python\"}'\n",
        "    elif tool_name == \"generate_tests\":\n",
        "        tool_input.value = '{\"code\": \"def add(a, b):\\\\n    return a + b\\\\n\\\\ndef subtract(a, b):\\\\n    return a - b\", \"language\": \"python\"}'\n",
        "    elif tool_name == \"action_agent\":\n",
        "        tool_input.value = '{\"task\": \"Write a Python function to calculate Fibonacci numbers\", \"context\": \"The function should be efficient\"}'\n",
        "    elif tool_name == \"summarize_text\":\n",
        "        tool_input.value = '{\"text\": \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\", \"max_length\": 50}'\n",
        "    elif tool_name == \"launch_site\":\n",
        "        tool_input.value = '{\"site_path\": \"my_site\", \"port\": 8000}'\n",
        "    elif tool_name == \"setup_frp\":\n",
        "        tool_input.value = '{\"local_port\": 8000, \"custom_domain\": \"manus-example.com\"}'\n",
        "    else:\n",
        "        tool_input.value = '{}'\n",
        "\n",
        "def on_tool_button_clicked(b):\n",
        "    tool_name = tool_dropdown.value\n",
        "    input_json = tool_input.value\n",
        "    \n",
        "    try:\n",
        "        input_dict = json.loads(input_json)\n",
        "    except json.JSONDecodeError as e:\n",
        "        with tool_output:\n",
        "            clear_output()\n",
        "            display(HTML(f\"<p>‚ùå Invalid JSON: {str(e)}</p>\"))\n",
        "        return\n",
        "    \n",
        "    with tool_output:\n",
        "        clear_output()\n",
        "        display(HTML(f\"<p><strong>Executing tool:</strong> {tool_name}</p>\"))\n",
        "        display(HTML(f\"<p><strong>Input:</strong> {input_json}</p>\"))\n",
        "        \n",
        "        # Execute the tool\n",
        "        if tool_name in TOOL_REGISTRY:\n",
        "            try:\n",
        "                result = TOOL_REGISTRY[tool_name](**input_dict)\n",
        "                display(HTML(format_tool_result(result)))\n",
        "            except Exception as e:\n",
        "                display(HTML(f\"<p>‚ùå Error executing tool: {str(e)}</p>\"))\n",
        "        else:\n",
        "            display(HTML(\"<p>‚ùå Tool not found.</p>\"))\n",
        "\n",
        "tool_dropdown.observe(on_tool_dropdown_change, names='value')\n",
        "tool_button.on_click(on_tool_button_clicked)\n",
        "\n",
        "# ===== CODE EDITOR INTERFACE =====\n",
        "\n",
        "code_editor = widgets.Textarea(\n",
        "    value='# Enter your Python code here\\nprint(\"Hello, world!\")',\n",
        "    placeholder='Enter Python code...',\n",
        "    description='Code:',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='100%', height='200px'),\n",
        "    style={'description_width': '100px'}\n",
        ")\n",
        "code_run_button = widgets.Button(\n",
        "    description='Run Code',\n",
        "    disabled=False,\n",
        "    button_style='success',\n",
        "    tooltip='Execute the code',\n",
        "    icon='play'\n",
        ")\n",
        "code_review_button = widgets.Button(\n",
        "    description='Review Code',\n",
        "    disabled=False,\n",
        "    button_style='info',\n",
        "    tooltip='Review the code for improvements',\n",
        "    icon='check'\n",
        ")\n",
        "code_test_button = widgets.Button(\n",
        "    description='Generate Tests',\n",
        "    disabled=False,\n",
        "    button_style='warning',\n",
        "    tooltip='Generate unit tests for the code',\n",
        "    icon='vial'\n",
        ")\n",
        "code_output = widgets.Output()\n",
        "\n",
        "code_buttons = widgets.HBox([code_run_button, code_review_button, code_test_button])\n",
        "code_interface = widgets.VBox([code_editor, code_buttons, code_output])\n",
        "\n",
        "# Code editor event handlers\n",
        "def on_code_run_button_clicked(b):\n",
        "    code = code_editor.value\n",
        "    \n",
        "    with code_output:\n",
        "        clear_output()\n",
        "        display(HTML(\"<p><strong>Executing code...</strong></p>\"))\n",
        "        \n",
        "        # Execute the code\n",
        "        if \"execute_python\" in TOOL_REGISTRY:\n",
        "            result = TOOL_REGISTRY[\"execute_python\"](code=code)\n",
        "            display(HTML(format_tool_result(result)))\n",
        "        else:\n",
        "            display(HTML(\"<p>‚ùå Code execution tool not available.</p>\"))\n",
        "\n",
        "def on_code_review_button_clicked(b):\n",
        "    code = code_editor.value\n",
        "    \n",
        "    with code_output:\n",
        "        clear_output()\n",
        "        display(HTML(\"<p><strong>Reviewing code...</strong></p>\"))\n",
        "        \n",
        "        # Review the code\n",
        "        if \"review_code\" in TOOL_REGISTRY:\n",
        "            result = TOOL_REGISTRY[\"review_code\"](code=code, language=\"python\")\n",
        "            display(HTML(format_tool_result(result)))\n",
        "        else:\n",
        "            display(HTML(\"<p>‚ùå Code review tool not available.</p>\"))\n",
        "\n",
        "def on_code_test_button_clicked(b):\n",
        "    code = code_editor.value\n",
        "    \n",
        "    with code_output:\n",
        "        clear_output()\n",
        "        display(HTML(\"<p><strong>Generating tests...</strong></p>\"))\n",
        "        \n",
        "        # Generate tests\n",
        "        if \"generate_tests\" in TOOL_REGISTRY:\n",
        "            result = TOOL_REGISTRY[\"generate_tests\"](code=code, language=\"python\")\n",
        "            display(HTML(format_tool_result(result)))\n",
        "        else:\n",
        "            display(HTML(\"<p>‚ùå Test generation tool not available.</p>\"))\n",
        "\n",
        "code_run_button.on_click(on_code_run_button_clicked)\n",
        "code_review_button.on_click(on_code_review_button_clicked)\n",
        "code_test_button.on_click(on_code_test_button_clicked)\n",
        "\n",
        "# ===== MODEL TYPE CHANGE HANDLER =====\n",
        "\n",
        "def on_model_type_change(change):\n",
        "    model_type = change['new']\n",
        "    \n",
        "    # Update model dropdowns\n",
        "    if model_type == \"google\":\n",
        "        google_model_dropdown.disabled = False\n",
        "        ollama_model_dropdown.disabled = True\n",
        "    elif model_type == \"ollama\":\n",
        "        google_model_dropdown.disabled = True\n",
        "        ollama_model_dropdown.disabled = False\n",
        "    else:  # fallback\n",
        "        google_model_dropdown.disabled = True\n",
        "        ollama_model_dropdown.disabled = True\n",
        "\n",
        "model_type_dropdown.observe(on_model_type_change, names='value')\n",
        "\n",
        "# ===== ASSEMBLE THE UI =====\n",
        "\n",
        "# Add tabs\n",
        "tab_contents = [chat_interface, task_interface, tool_interface, code_interface]\n",
        "tab.children = tab_contents\n",
        "tab.set_title(0, \"Chat\")\n",
        "tab.set_title(1, \"Task Execution\")\n",
        "tab.set_title(2, \"Tool Execution\")\n",
        "tab.set_title(3, \"Code Editor\")\n",
        "\n",
        "# Model controls\n",
        "model_controls = widgets.HBox([model_type_dropdown, google_model_dropdown, ollama_model_dropdown, human_review_toggle])\n",
        "\n",
        "# Main UI\n",
        "main_ui = widgets.VBox([header, model_controls, tab])\n",
        "\n",
        "# Display the UI\n",
        "display(main_ui)\n",
        "\n",
        "# Initialize the chat interface\n",
        "with chat_output:\n",
        "    display(HTML(\"<p>Welcome to Google Manus System! How can I help you today?</p>\"))\n",
        "\n",
        "print(\"\\nüéâ BOX 4 SETUP COMPLETED SUCCESSFULLY!\")\n",
        "print(\"üñ•Ô∏è User Interface Initialized\")\n",
        "print(\"üí¨ Chat Interface Ready\")\n",
        "print(\"üéØ Task Execution Ready\")\n",
        "print(\"üõ†Ô∏è Tool Execution Ready\")\n",
        "print(\"üíª Code Editor Ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "box5-header"
      },
      "source": [
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "# ‚ïë üåê BOX 5: Web Deployment and External Services - v1.0                                                     ‚ïë\n",
        "# ‚ïë                                                                                                          ‚ïë\n",
        "# ‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CORE FEATURES ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n",
        "# ‚ïë - FastAPI server setup                                                                                   ‚ïë\n",
        "# ‚ïë - FRP tunnel integration                                                                                 ‚ïë\n",
        "# ‚ïë - Static file serving                                                                                    ‚ïë\n",
        "# ‚ïë - Web-based code execution environment                                                                   ‚ïë\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "box5-code"
      },
      "outputs": [],
      "source": [
        "print(\"üåê BOX 5: Initializing Web Deployment and External Services...\")\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import asyncio\n",
        "import threading\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any, Optional, Union, Callable\n",
        "\n",
        "# Load configuration from previous boxes\n",
        "try:\n",
        "    with open(Path(\"./GoogleManusSystem/config/box1_exports.json\"), \"r\") as f:\n",
        "        box1_exports = json.load(f)\n",
        "    \n",
        "    with open(Path(\"./GoogleManusSystem/config/box2_exports.json\"), \"r\") as f:\n",
        "        box2_exports = json.load(f)\n",
        "    \n",
        "    with open(Path(\"./GoogleManusSystem/config/box3_exports.json\"), \"r\") as f:\n",
        "        box3_exports = json.load(f)\n",
        "    \n",
        "    # Extract configuration\n",
        "    BASE_DIR = Path(box1_exports[\"BASE_DIR\"])\n",
        "    WORKSPACE_DIR = Path(box1_exports[\"WORKSPACE_DIR\"])\n",
        "    SITES_DIR = Path(box1_exports[\"SITES_DIR\"])\n",
        "    HUMAN_REVIEW_DIR = Path(box1_exports[\"HUMAN_REVIEW_DIR\"])\n",
        "    IS_COLAB = box1_exports[\"IS_COLAB\"]\n",
        "    config = box1_exports[\"config\"]\n",
        "    \n",
        "    default_model = box2_exports[\"default_model\"]\n",
        "    default_model_type = box2_exports[\"default_model_type\"]\n",
        "    GOOGLE_AI_AVAILABLE = box2_exports[\"google_ai_available\"]\n",
        "    OLLAMA_AVAILABLE = box2_exports[\"ollama_available\"]\n",
        "    \n",
        "    tools_registered = box3_exports[\"tools_registered\"]\n",
        "    \n",
        "    print(\"‚úÖ Loaded configuration from previous boxes\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading previous box configurations: {e}\")\n",
        "    print(\"‚ö†Ô∏è Using default configuration\")\n",
        "    \n",
        "    # Default configuration if previous boxes haven't been run\n",
        "    BASE_DIR = Path(\"./GoogleManusSystem\")\n",
        "    WORKSPACE_DIR = BASE_DIR / \"workspace\"\n",
        "    SITES_DIR = BASE_DIR / \"sites\"\n",
        "    HUMAN_REVIEW_DIR = BASE_DIR / \"human_review\"\n",
        "    IS_COLAB = True\n",
        "    config = {\"human_review_enabled\": True, \"auto_approve_threshold\": 0.8}\n",
        "    \n",
        "    default_model = \"google/gemini-2.5-pro\"\n",
        "    default_model_type = \"google\"\n",
        "    GOOGLE_AI_AVAILABLE = False\n",
        "    OLLAMA_AVAILABLE = False\n",
        "    \n",
        "    tools_registered = [\"write_file\", \"read_file\", \"list_files\", \"execute_python\", \"action_agent\"]\n",
        "\n",
        "# Import functions from previous boxes\n",
        "try:\n",
        "    from __main__ import generate_text, chat, memory, call_tool, TOOL_REGISTRY, model_adapter\n",
        "    print(\"‚úÖ Imported functions from previous boxes\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Error importing functions: {e}\")\n",
        "    print(\"‚ö†Ô∏è Web server will have limited functionality\")\n",
        "    \n",
        "    # Define placeholder functions\n",
        "    async def generate_text(prompt, model_name=None, model_type=None, stream=False):\n",
        "        return f\"[PLACEHOLDER] Would generate text for: {prompt[:50]}...\"\n",
        "    \n",
        "    async def chat(message, conversation_id=None, model_name=None, model_type=None, stream=False):\n",
        "        return f\"[PLACEHOLDER] Would chat about: {message[:50]}...\", 0.5\n",
        "    \n",
        "    class MemorySystem:\n",
        "        def get_conversation(self, conversation_id=None):\n",
        "            return []\n",
        "        \n",
        "        def add_message(self, role, content, conversation_id=None):\n",
        "            pass\n",
        "        \n",
        "        def clear_conversation(self, conversation_id=None):\n",
        "            pass\n",
        "    \n",
        "    memory = MemorySystem()\n",
        "    \n",
        "    class ToolCall:\n",
        "        def __init__(self, tool_name, tool_input):\n",
        "            self.tool_name = tool_name\n",
        "            self.tool_input = tool_input\n",
        "    \n",
        "    async def call_tool(tool_call):\n",
        "        return {\"error\": \"Tool execution not available\"}\n",
        "    \n",
        "    TOOL_REGISTRY = {}\n",
        "    for tool in tools_registered:\n",
        "        TOOL_REGISTRY[tool] = lambda **kwargs: {\"error\": \"Tool not implemented\"}\n",
        "    \n",
        "    class ModelAdapter:\n",
        "        def __init__(self):\n",
        "            pass\n",
        "        \n",
        "        async def generate_response(self, prompt, model_type=None, model_name=None, stream=False):\n",
        "            return f\"[PLACEHOLDER] Would generate response for: {prompt[:50]}...\", 0.5\n",
        "        \n",
        "        def list_available_models(self):\n",
        "            return []\n",
        "    \n",
        "    model_adapter = ModelAdapter()\n",
        "\n",
        "# Create FastAPI server\n",
        "from fastapi import FastAPI, Request, BackgroundTasks, HTTPException, Depends, Form, File, UploadFile\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi.staticfiles import StaticFiles\n",
        "from fastapi.responses import JSONResponse, HTMLResponse, FileResponse, StreamingResponse\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "\n",
        "app = FastAPI(title=\"Google Manus API\", description=\"API for Google Manus System\", version=\"1.0.0\")\n",
        "\n",
        "# Add CORS middleware\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# API models\n",
        "class ChatRequest(BaseModel):\n",
        "    message: str\n",
        "    conversation_id: Optional[str] = None\n",
        "    model_name: Optional[str] = None\n",
        "    model_type: Optional[str] = None\n",
        "    user_id: Optional[str] = None\n",
        "\n",
        "class ToolRequest(BaseModel):\n",
        "    tool_name: str\n",
        "    tool_input: Dict[str, Any] = {}\n",
        "\n",
        "class TaskRequest(BaseModel):\n",
        "    task: str\n",
        "    context: Optional[str] = None\n",
        "    model_name: Optional[str] = None\n",
        "    model_type: Optional[str] = None\n",
        "\n",
        "class ReviewSubmission(BaseModel):\n",
        "    review_id: str\n",
        "    approved: bool\n",
        "    modified_response: Optional[str] = None\n",
        "\n",
        "# Message queue for human review\n",
        "class MessageQueue:\n",
        "    def __init__(self):\n",
        "        self.messages = {}\n",
        "        self.next_id = 1\n",
        "        \n",
        "        # Load existing messages if available\n",
        "        queue_file = HUMAN_REVIEW_DIR / \"message_queue.json\"\n",
        "        if queue_file.exists():\n",
        "            try:\n",
        "                with open(queue_file, \"r\") as f:\n",
        "                    data = json.load(f)\n",
        "                    self.messages = data.get(\"messages\", {})\n",
        "                    self.next_id = data.get(\"next_id\", 1)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading message queue: {e}\")\n",
        "    \n",
        "    def add_message(self, user_id, message, ai_response, confidence, conversation_id=None):\n",
        "        \"\"\"Add a message to the queue.\"\"\"\n",
        "        review_id = str(self.next_id)\n",
        "        self.next_id += 1\n",
        "        \n",
        "        self.messages[review_id] = {\n",
        "            \"user_id\": user_id,\n",
        "            \"message\": message,\n",
        "            \"ai_response\": ai_response,\n",
        "            \"confidence\": confidence,\n",
        "            \"conversation_id\": conversation_id,\n",
        "            \"status\": \"pending\",\n",
        "            \"created_at\": time.time(),\n",
        "            \"final_response\": None\n",
        "        }\n",
        "        \n",
        "        # Save to file\n",
        "        self._save_to_file()\n",
        "        \n",
        "        return review_id\n",
        "    \n",
        "    def get_message(self, review_id):\n",
        "        \"\"\"Get a message by ID.\"\"\"\n",
        "        return self.messages.get(review_id)\n",
        "    \n",
        "    def update_message(self, review_id, status, final_response=None):\n",
        "        \"\"\"Update a message's status and final response.\"\"\"\n",
        "        if review_id in self.messages:\n",
        "            self.messages[review_id][\"status\"] = status\n",
        "            if final_response:\n",
        "                self.messages[review_id][\"final_response\"] = final_response\n",
        "            self.messages[review_id][\"updated_at\"] = time.time()\n",
        "            \n",
        "            # Save to file\n",
        "            self._save_to_file()\n",
        "            \n",
        "            return True\n",
        "        return False\n",
        "    \n",
        "    def get_pending_messages(self, limit=10):\n",
        "        \"\"\"Get pending messages awaiting review.\"\"\"\n",
        "        pending = [\n",
        "            {\"review_id\": review_id, **message}\n",
        "            for review_id, message in self.messages.items()\n",
        "            if message[\"status\"] == \"pending\"\n",
        "        ]\n",
        "        \n",
        "        # Sort by creation time (oldest first)\n",
        "        pending.sort(key=lambda x: x[\"created_at\"])\n",
        "        \n",
        "        return pending[:limit]\n",
        "    \n",
        "    def _save_to_file(self):\n",
        "        \"\"\"Save the message queue to a file.\"\"\"\n",
        "        queue_file = HUMAN_REVIEW_DIR / \"message_queue.json\"\n",
        "        with open(queue_file, \"w\") as f:\n",
        "            json.dump({\"messages\": self.messages, \"next_id\": self.next_id}, f, indent=2)\n",
        "\n",
        "# Initialize message queue\n",
        "message_queue = MessageQueue()\n",
        "\n",
        "# Chat router for human-in-the-loop\n",
        "class ChatRouter:\n",
        "    def __init__(self, model_adapter, message_queue, human_review_enabled=True, auto_approve_threshold=0.8):\n",
        "        self.model_adapter = model_adapter\n",
        "        self.message_queue = message_queue\n",
        "        self.human_review_enabled = human_review_enabled\n",
        "        self.auto_approve_threshold = auto_approve_threshold\n",
        "    \n",
        "    async def process_message(self, user_id, message, conversation_id=None, model_name=None, model_type=None):\n",
        "        \"\"\"Process an incoming user message.\"\"\"\n",
        "        # Generate AI response\n",
        "        ai_response, confidence = await self.model_adapter.generate_response(\n",
        "            prompt=message,\n",
        "            model_type=model_type,\n",
        "            model_name=model_name\n",
        "        )\n",
        "        \n",
        "        # Add user message to memory\n",
        "        memory.add_message(\"user\", message, conversation_id)\n",
        "        \n",
        "        if not self.human_review_enabled or confidence >= self.auto_approve_threshold:\n",
        "            # Auto-approve high-confidence responses\n",
        "            memory.add_message(\"assistant\", ai_response, conversation_id)\n",
        "            return {\"response\": ai_response, \"confidence\": confidence, \"reviewed\": False}\n",
        "        \n",
        "        # Queue for human review\n",
        "        review_id = self.message_queue.add_message(\n",
        "            user_id=user_id,\n",
        "            message=message,\n",
        "            ai_response=ai_response,\n",
        "            confidence=confidence,\n",
        "            conversation_id=conversation_id\n",
        "        )\n",
        "        \n",
        "        # Return a temporary response\n",
        "        return {\n",
        "            \"status\": \"pending_review\",\n",
        "            \"review_id\": review_id,\n",
        "            \"confidence\": confidence,\n",
        "            \"message\": \"Your message is being reviewed by a human operator.\"\n",
        "        }\n",
        "    \n",
        "    async def get_pending_reviews(self, limit=10):\n",
        "        \"\"\"Get pending messages awaiting human review.\"\"\"\n",
        "        return self.message_queue.get_pending_messages(limit)\n",
        "    \n",
        "    async def submit_human_review(self, review_id, approved, modified_response=None):\n",
        "        \"\"\"Submit human review for a message.\"\"\"\n",
        "        message = self.message_queue.get_message(review_id)\n",
        "        if not message:\n",
        "            return {\"error\": \"Message not found\"}\n",
        "        \n",
        "        final_response = modified_response if modified_response else message[\"ai_response\"]\n",
        "        \n",
        "        # Update message status\n",
        "        self.message_queue.update_message(\n",
        "            review_id=review_id,\n",
        "            status=\"approved\" if approved else \"rejected\",\n",
        "            final_response=final_response\n",
        "        )\n",
        "        \n",
        "        # If approved, add to memory\n",
        "        if approved:\n",
        "            memory.add_message(\"assistant\", final_response, message[\"conversation_id\"])\n",
        "        \n",
        "        return {\"status\": \"success\", \"approved\": approved}\n",
        "\n",
        "# Initialize chat router\n",
        "chat_router = ChatRouter(\n",
        "    model_adapter=model_adapter,\n",
        "    message_queue=message_queue,\n",
        "    human_review_enabled=config.get(\"human_review_enabled\", True),\n",
        "    auto_approve_threshold=config.get(\"auto_approve_threshold\", 0.8)\n",
        ")\n",
        "\n",
        "# API routes\n",
        "@app.get(\"/\", response_class=HTMLResponse)\n",
        "async def root():\n",
        "    return \"\"\"\n",
        "    <html>\n",
        "        <head>\n",
        "            <title>Google Manus API</title>\n",
        "            <style>\n",
        "                body { font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }\n",
        "                h1 { color: #4285F4; }\n",
        "                h2 { color: #34A853; margin-top: 30px; }\n",
        "                pre { background-color: #f5f5f5; padding: 10px; border-radius: 5px; }\n",
        "                .endpoint { margin-bottom: 20px; }\n",
        "            </style>\n",
        "        </head>\n",
        "        <body>\n",
        "            <h1>ü§ñ Google Manus API</h1>\n",
        "            <p>Welcome to the Google Manus API. Use the following endpoints to interact with the system:</p>\n",
        "            \n",
        "            <div class=\"endpoint\">\n",
        "                <h2>üìã API Documentation</h2>\n",
        "                <p>View the full API documentation at <a href=\"/docs\">/docs</a></p>\n",
        "            </div>\n",
        "            \n",
        "            <div class=\"endpoint\">\n",
        "                <h2>üí¨ Chat</h2>\n",
        "                <p>Send a message to the model:</p>\n",
        "                <pre>POST /api/chat\n",
        "{\n",
        "    \"message\": \"Hello, how are you?\",\n",
        "    \"conversation_id\": \"optional-id\",\n",
        "    \"model_name\": \"optional-model-name\",\n",
        "    \"model_type\": \"google|ollama\"\n",
        "}</pre>\n",
        "            </div>\n",
        "            \n",
        "            <div class=\"endpoint\">\n",
        "                <h2>üë§ Human-in-the-Loop Chat</h2>\n",
        "                <p>Send a message for human review:</p>\n",
        "                <pre>POST /api/chat/human-review\n",
        "{\n",
        "    \"message\": \"Hello, how are you?\",\n",
        "    \"conversation_id\": \"optional-id\",\n",
        "    \"model_name\": \"optional-model-name\",\n",
        "    \"model_type\": \"google|ollama\",\n",
        "    \"user_id\": \"optional-user-id\"\n",
        "}</pre>\n",
        "            </div>\n",
        "            \n",
        "            <div class=\"endpoint\">\n",
        "                <h2>üõ†Ô∏è Tool Execution</h2>\n",
        "                <p>Execute a tool:</p>\n",
        "                <pre>POST /api/tool\n",
        "{\n",
        "    \"tool_name\": \"write_file\",\n",
        "    \"tool_input\": {\n",
        "        \"file_path\": \"example.txt\",\n",
        "        \"content\": \"Hello, world!\"\n",
        "    }\n",
        "}</pre>\n",
        "            </div>\n",
        "            \n",
        "            <div class=\"endpoint\">\n",
        "                <h2>üéØ Task Execution</h2>\n",
        "                <p>Execute a task:</p>\n",
        "                <pre>POST /api/task\n",
        "{\n",
        "    \"task\": \"Write a Python function to calculate Fibonacci numbers\",\n",
        "    \"context\": \"The function should be efficient\",\n",
        "    \"model_name\": \"optional-model-name\",\n",
        "    \"model_type\": \"google|ollama\"\n",
        "}</pre>\n",
        "            </div>\n",
        "            \n",
        "            <div class=\"endpoint\">\n",
        "                <h2>üß† Models</h2>\n",
        "                <p>List available models:</p>\n",
        "                <pre>GET /api/models</pre>\n",
        "            </div>\n",
        "            \n",
        "            <div class=\"endpoint\">\n",
        "                <h2>üõ†Ô∏è Tools</h2>\n",
        "                <p>List available tools:</p>\n",
        "                <pre>GET /api/tools</pre>\n",
        "            </div>\n",
        "            \n",
        "            <div class=\"endpoint\">\n",
        "                <h2>üë§ Human Review</h2>\n",
        "                <p>Get pending reviews:</p>\n",
        "                <pre>GET /api/reviews/pending</pre>\n",
        "                <p>Submit a review:</p>\n",
        "                <pre>POST /api/reviews/submit\n",
        "{\n",
        "    \"review_id\": \"1\",\n",
        "    \"approved\": true,\n",
        "    \"modified_response\": \"Optional modified response\"\n",
        "}</pre>\n",
        "            </div>\n",
        "        </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "@app.get(\"/api/models\")\n",
        "async def get_models():\n",
        "    \"\"\"List available models.\"\"\"\n",
        "    models = model_adapter.list_available_models()\n",
        "    return {\n",
        "        \"models\": models,\n",
        "        \"default_model\": default_model,\n",
        "        \"default_model_type\": default_model_type\n",
        "    }\n",
        "\n",
        "@app.get(\"/api/tools\")\n",
        "async def get_tools():\n",
        "    \"\"\"List available tools.\"\"\"\n",
        "    return {\"tools\": tools_registered}\n",
        "\n",
        "@app.post(\"/api/chat\")\n",
        "async def api_chat(request: ChatRequest):\n",
        "    \"\"\"Chat with the model.\"\"\"\n",
        "    try:\n",
        "        response, confidence = await chat(\n",
        "            message=request.message,\n",
        "            conversation_id=request.conversation_id,\n",
        "            model_name=request.model_name,\n",
        "            model_type=request.model_type\n",
        "        )\n",
        "        return {\"response\": response, \"confidence\": confidence}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.post(\"/api/chat/human-review\")\n",
        "async def api_chat_with_review(request: ChatRequest):\n",
        "    \"\"\"Chat with human review.\"\"\"\n",
        "    try:\n",
        "        result = await chat_router.process_message(\n",
        "            user_id=request.user_id or \"anonymous\",\n",
        "            message=request.message,\n",
        "            conversation_id=request.conversation_id,\n",
        "            model_name=request.model_name,\n",
        "            model_type=request.model_type\n",
        "        )\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.post(\"/api/tool\")\n",
        "async def api_tool(request: ToolRequest):\n",
        "    \"\"\"Execute a tool.\"\"\"\n",
        "    try:\n",
        "        if request.tool_name not in TOOL_REGISTRY:\n",
        "            raise HTTPException(status_code=404, detail=f\"Tool {request.tool_name} not found\")\n",
        "        \n",
        "        result = TOOL_REGISTRY[request.tool_name](**request.tool_input)\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.post(\"/api/task\")\n",
        "async def api_task(request: TaskRequest):\n",
        "    \"\"\"Execute a task.\"\"\"\n",
        "    try:\n",
        "        if \"action_agent\" not in TOOL_REGISTRY:\n",
        "            raise HTTPException(status_code=404, detail=\"Action agent tool not found\")\n",
        "        \n",
        "        result = TOOL_REGISTRY[\"action_agent\"](task=request.task, context=request.context)\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.get(\"/api/reviews/pending\")\n",
        "async def get_pending_reviews(limit: int = 10):\n",
        "    \"\"\"Get pending messages awaiting human review.\"\"\"\n",
        "    try:\n",
        "        pending_messages = await chat_router.get_pending_reviews(limit)\n",
        "        return {\"reviews\": pending_messages}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.post(\"/api/reviews/submit\")\n",
        "async def submit_review(submission: ReviewSubmission):\n",
        "    \"\"\"Submit a human review for a message.\"\"\"\n",
        "    try:\n",
        "        result = await chat_router.submit_human_review(\n",
        "            review_id=submission.review_id,\n",
        "            approved=submission.approved,\n",
        "            modified_response=submission.modified_response\n",
        "        )\n",
        "        \n",
        "        if \"error\" in result:\n",
        "            return {\"status\": \"error\", \"error\": result[\"error\"]}\n",
        "        \n",
        "        return {\"status\": \"success\", \"approved\": submission.approved}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "# Mount static files for sites\n",
        "app.mount(\"/site\", StaticFiles(directory=str(SITES_DIR)), name=\"sites\")\n",
        "\n",
        "# Create a simple site launcher\n",
        "@app.get(\"/site/launch/{site_name}\")\n",
        "async def launch_site(site_name: str):\n",
        "    site_path = SITES_DIR / site_name\n",
        "    \n",
        "    if not site_path.exists():\n",
        "        site_path.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        # Create a simple index.html\n",
        "        index_path = site_path / \"index.html\"\n",
        "        with open(index_path, \"w\") as f:\n",
        "            f.write(f\"\"\"\n",
        "            <!DOCTYPE html>\n",
        "            <html>\n",
        "            <head>\n",
        "                <title>{site_name} - Google Manus Site</title>\n",
        "                <style>\n",
        "                    body {{ font-family: Arial, sans-serif; margin: 40px; }}\n",
        "                    h1 {{ color: #4285F4; }}\n",
        "                </style>\n",
        "            </head>\n",
        "            <body>\n",
        "                <h1>Welcome to {site_name}</h1>\n",
        "                <p>This is a simple website launched by Google Manus System.</p>\n",
        "                <p>Current time: {time.strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
        "            </body>\n",
        "            </html>\n",
        "            \"\"\")\n",
        "    \n",
        "    # Return the index.html file\n",
        "    return FileResponse(site_path / \"index.html\")\n",
        "\n",
        "# Human review interface\n",
        "@app.get(\"/human-review\", response_class=HTMLResponse)\n",
        "async def human_review_interface():\n",
        "    \"\"\"Web interface for human review.\"\"\"\n",
        "    return \"\"\"\n",
        "    <html>\n",
        "        <head>\n",
        "            <title>Human Review Interface</title>\n",
        "            <style>\n",
        "                body { font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }\n",
        "                h1 { color: #4285F4; }\n",
        "                h2 { color: #34A853; margin-top: 30px; }\n",
        "                .review-item { border: 1px solid #ddd; padding: 15px; margin-bottom: 20px; border-radius: 5px; }\n",
        "                .user-message { background-color: #e6f7ff; padding: 10px; border-radius: 5px; margin: 10px 0; }\n",
        "                .ai-response { background-color: #f0f0f0; padding: 10px; border-radius: 5px; margin: 10px 0; }\n",
        "                .confidence { color: #666; }\n",
        "                .actions { margin-top: 15px; }\n",
        "                button { padding: 8px 16px; margin-right: 10px; border-radius: 4px; cursor: pointer; }\n",
        "                .approve { background-color: #34A853; color: white; border: none; }\n",
        "                .reject { background-color: #EA4335; color: white; border: none; }\n",
        "                .refresh { background-color: #4285F4; color: white; border: none; }\n",
        "                textarea { width: 100%; height: 100px; margin-top: 10px; padding: 8px; border-radius: 4px; border: 1px solid #ddd; }\n",
        "                #pending-reviews { margin-top: 20px; }\n",
        "            </style>\n",
        "        </head>\n",
        "        <body>\n",
        "            <h1>üß† Human Review Interface</h1>\n",
        "            <p>Review and approve AI-generated responses before they are sent to users.</p>\n",
        "            \n",
        "            <button class=\"refresh\" onclick=\"loadPendingReviews()\">Refresh Pending Reviews</button>\n",
        "            \n",
        "            <div id=\"pending-reviews\">\n",
        "                <p>Loading pending reviews...</p>\n",
        "            </div>\n",
        "            \n",
        "            <script>\n",
        "                // Load pending reviews\n",
        "                function loadPendingReviews() {\n",
        "                    fetch('/api/reviews/pending')\n",
        "                        .then(response => response.json())\n",
        "                        .then(data => {\n",
        "                            const pendingReviews = document.getElementById('pending-reviews');\n",
        "                            \n",
        "                            if (data.reviews.length === 0) {\n",
        "                                pendingReviews.innerHTML = '<p>No pending reviews.</p>';\n",
        "                                return;\n",
        "                            }\n",
        "                            \n",
        "                            let html = '';\n",
        "                            data.reviews.forEach(review => {\n",
        "                                html += `\n",
        "                                    <div class=\"review-item\" id=\"review-${review.review_id}\">\n",
        "                                        <h3>Review #${review.review_id}</h3>\n",
        "                                        <p><strong>User:</strong> ${review.user_id}</p>\n",
        "                                        <p><strong>Created:</strong> ${new Date(review.created_at * 1000).toLocaleString()}</p>\n",
        "                                        <p class=\"confidence\"><strong>Confidence:</strong> ${review.confidence.toFixed(2)}</p>\n",
        "                                        \n",
        "                                        <div class=\"user-message\">\n",
        "                                            <strong>User Message:</strong>\n",
        "                                            <div>${review.message}</div>\n",
        "                                        </div>\n",
        "                                        \n",
        "                                        <div class=\"ai-response\">\n",
        "                                            <strong>AI Response:</strong>\n",
        "                                            <div>${review.ai_response}</div>\n",
        "                                        </div>\n",
        "                                        \n",
        "                                        <textarea id=\"modified-${review.review_id}\" placeholder=\"Edit the response if needed...\">${review.ai_response}</textarea>\n",
        "                                        \n",
        "                                        <div class=\"actions\">\n",
        "                                            <button class=\"approve\" onclick=\"approveReview('${review.review_id}')\">Approve</button>\n",
        "                                            <button class=\"reject\" onclick=\"rejectReview('${review.review_id}')\">Reject</button>\n",
        "                                        </div>\n",
        "                                    </div>\n",
        "                                `;\n",
        "                            });\n",
        "                            \n",
        "                            pendingReviews.innerHTML = html;\n",
        "                        })\n",
        "                        .catch(error => {\n",
        "                            console.error('Error loading reviews:', error);\n",
        "                            document.getElementById('pending-reviews').innerHTML = `<p>Error loading reviews: ${error.message}</p>`;\n",
        "                        });\n",
        "                }\n",
        "                \n",
        "                // Approve a review\n",
        "                function approveReview(reviewId) {\n",
        "                    const modifiedResponse = document.getElementById(`modified-${reviewId}`).value;\n",
        "                    \n",
        "                    fetch('/api/reviews/submit', {\n",
        "                        method: 'POST',\n",
        "                        headers: {\n",
        "                            'Content-Type': 'application/json'\n",
        "                        },\n",
        "                        body: JSON.stringify({\n",
        "                            review_id: reviewId,\n",
        "                            approved: true,\n",
        "                            modified_response: modifiedResponse\n",
        "                        })\n",
        "                    })\n",
        "                    .then(response => response.json())\n",
        "                    .then(data => {\n",
        "                        if (data.status === 'success') {\n",
        "                            document.getElementById(`review-${reviewId}`).innerHTML = `<p>Review #${reviewId} approved successfully.</p>`;\n",
        "                            setTimeout(() => loadPendingReviews(), 1000);\n",
        "                        } else {\n",
        "                            alert(`Error: ${data.error || 'Unknown error'}`)\n",
        "                        }\n",
        "                    })\n",
        "                    .catch(error => {\n",
        "                        console.error('Error approving review:', error);\n",
        "                        alert(`Error approving review: ${error.message}`);\n",
        "                    });\n",
        "                }\n",
        "                \n",
        "                // Reject a review\n",
        "                function rejectReview(reviewId) {\n",
        "                    fetch('/api/reviews/submit', {\n",
        "                        method: 'POST',\n",
        "                        headers: {\n",
        "                            'Content-Type': 'application/json'\n",
        "                        },\n",
        "                        body: JSON.stringify({\n",
        "                            review_id: reviewId,\n",
        "                            approved: false\n",
        "                        })\n",
        "                    })\n",
        "                    .then(response => response.json())\n",
        "                    .then(data => {\n",
        "                        if (data.status === 'success') {\n",
        "                            document.getElementById(`review-${reviewId}`).innerHTML = `<p>Review #${reviewId} rejected successfully.</p>`;\n",
        "                            setTimeout(() => loadPendingReviews(), 1000);\n",
        "                        } else {\n",
        "                            alert(`Error: ${data.error || 'Unknown error'}`)\n",
        "                        }\n",
        "                    })\n",
        "                    .catch(error => {\n",
        "                        console.error('Error rejecting review:', error);\n",
        "                        alert(`Error rejecting review: ${error.message}`);\n",
        "                    });\n",
        "                }\n",
        "                \n",
        "                // Load reviews on page load\n",
        "                document.addEventListener('DOMContentLoaded', loadPendingReviews);\n",
        "            </script>\n",
        "        </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "# Setup FRP tunnel\n",
        "def setup_frp(port: int = 8000):\n",
        "    \"\"\"Setup FRP tunnel for public access.\"\"\"\n",
        "    try:\n",
        "        # Download FRP if not exists\n",
        "        frp_dir = BASE_DIR / \"frp\"\n",
        "        if not frp_dir.exists():\n",
        "            print(\"‚è≥ Downloading FRP...\")\n",
        "            os.makedirs(frp_dir, exist_ok=True)\n",
        "            subprocess.run([\"wget\", \"https://github.com/fatedier/frp/releases/download/v0.51.3/frp_0.51.3_linux_amd64.tar.gz\", \"-O\", str(frp_dir / \"frp.tar.gz\")])\n",
        "            subprocess.run([\"tar\", \"-xzf\", str(frp_dir / \"frp.tar.gz\"), \"-C\", str(frp_dir), \"--strip-components=1\"])\n",
        "            os.remove(str(frp_dir / \"frp.tar.gz\"))\n",
        "            print(\"‚úÖ FRP downloaded and extracted\")\n",
        "        \n",
        "        # Create FRP config\n",
        "        frp_config = f\"\"\"\n",
        "[common]\n",
        "server_addr = frp.example.com\n",
        "server_port = 7000\n",
        "token = your_token_here\n",
        "\n",
        "[web]\n",
        "type = http\n",
        "local_port = {port}\n",
        "custom_domains = your-domain.example.com\n",
        "        \"\"\"\n",
        "        \n",
        "        with open(frp_dir / \"frpc.ini\", \"w\") as f:\n",
        "            f.write(frp_config)\n",
        "        \n",
        "        print(\"‚ö†Ô∏è FRP configuration created, but not started\")\n",
        "        print(\"‚ÑπÔ∏è To use FRP, you need to configure a real FRP server\")\n",
        "        print(f\"‚ÑπÔ∏è Edit the configuration file at {frp_dir / 'frpc.ini'}\")\n",
        "        print(f\"‚ÑπÔ∏è Then run: {frp_dir / 'frpc'} -c {frp_dir / 'frpc.ini'}\")\n",
        "        \n",
        "        return {\"success\": True, \"message\": \"FRP configuration created\"}\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error setting up FRP: {e}\")\n",
        "        return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "# Start the server in a separate thread\n",
        "def start_server():\n",
        "    \"\"\"Start the FastAPI server.\"\"\"\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "# Setup FRP\n",
        "frp_result = setup_frp()\n",
        "\n",
        "# Start the server in a background thread\n",
        "server_thread = threading.Thread(target=start_server)\n",
        "server_thread.daemon = True  # Allow the thread to be terminated when the notebook is closed\n",
        "server_thread.start()\n",
        "\n",
        "# Export configuration for other boxes\n",
        "box5_exports = {\n",
        "    \"server_started\": True,\n",
        "    \"server_port\": 8000,\n",
        "    \"frp_configured\": frp_result[\"success\"],\n",
        "    \"human_review_enabled\": config.get(\"human_review_enabled\", True)\n",
        "}\n",
        "\n",
        "box5_exports_file = CONFIG_DIR / \"box5_exports.json\"\n",
        "with open(box5_exports_file, \"w\") as f:\n",
        "    json.dump(box5_exports, f, indent=2)\n",
        "\n",
        "print(\"\\nüéâ BOX 5 SETUP COMPLETED SUCCESSFULLY!\")\n",
        "print(\"üåê Web Server Started at http://localhost:8000\")\n",
        "print(\"üìö API Documentation available at http://localhost:8000/docs\")\n",
        "print(\"üë§ Human Review Interface available at http://localhost:8000/human-review\")\n",
        "print(\"üöÄ Site Launcher available at http://localhost:8000/site/launch/{site_name}\")\n",
        "print(\"‚öôÔ∏è FRP Configuration Created (Manual Setup Required)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "box6-header"
      },
      "source": [
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "# ‚ïë üë§ BOX 6: Human-in-the-Loop System - v1.0                                                                ‚ïë\n",
        "# ‚ïë                                                                                                          ‚ïë\n",
        "# ‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CORE FEATURES ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n",
        "# ‚ïë - Human review interface                                                                                 ‚ïë\n",
        "# ‚ïë - Message queue management                                                                               ‚ïë\n",
        "# ‚ïë - Response approval workflow                                                                             ‚ïë\n",
        "# ‚ïë - Confidence threshold configuration                                                                     ‚ïë\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "box6-code"
      },
      "outputs": [],
      "source": [
        "print(\"üë§ BOX 6: Initializing Human-in-the-Loop System...\")\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import asyncio\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any, Optional, Union, Callable\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "# Load configuration from previous boxes\n",
        "try:\n",
        "    with open(Path(\"./GoogleManusSystem/config/box1_exports.json\"), \"r\") as f:\n",
        "        box1_exports = json.load(f)\n",
        "    \n",
        "    with open(Path(\"./GoogleManusSystem/config/box5_exports.json\"), \"r\") as f:\n",
        "        box5_exports = json.load(f)\n",
        "    \n",
        "    # Extract configuration\n",
        "    HUMAN_REVIEW_DIR = Path(box1_exports[\"HUMAN_REVIEW_DIR\"])\n",
        "    config = box1_exports[\"config\"]\n",
        "    \n",
        "    human_review_enabled = config.get(\"human_review_enabled\", True)\n",
        "    auto_approve_threshold = config.get(\"auto_approve_threshold\", 0.8)\n",
        "    server_started = box5_exports.get(\"server_started\", False)\n",
        "    server_port = box5_exports.get(\"server_port\", 8000)\n",
        "    \n",
        "    print(\"‚úÖ Loaded configuration from previous boxes\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading previous box configurations: {e}\")\n",
        "    print(\"‚ö†Ô∏è Using default configuration\")\n",
        "    \n",
        "    # Default configuration if previous boxes haven't been run\n",
        "    HUMAN_REVIEW_DIR = Path(\"./GoogleManusSystem/human_review\")\n",
        "    human_review_enabled = True\n",
        "    auto_approve_threshold = 0.8\n",
        "    server_started = False\n",
        "    server_port = 8000\n",
        "\n",
        "# Import functions from previous boxes\n",
        "try:\n",
        "    from __main__ import message_queue, chat_router\n",
        "    print(\"‚úÖ Imported functions from previous boxes\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Error importing functions: {e}\")\n",
        "    print(\"‚ö†Ô∏è Human review interface will have limited functionality\")\n",
        "    \n",
        "    # Define placeholder classes\n",
        "    class MessageQueue:\n",
        "        def __init__(self):\n",
        "            self.messages = {}\n",
        "            self.next_id = 1\n",
        "        \n",
        "        def add_message(self, user_id, message, ai_response, confidence, conversation_id=None):\n",
        "            review_id = str(self.next_id)\n",
        "            self.next_id += 1\n",
        "            \n",
        "            self.messages[review_id] = {\n",
        "                \"user_id\": user_id,\n",
        "                \"message\": message,\n",
        "                \"ai_response\": ai_response,\n",
        "                \"confidence\": confidence,\n",
        "                \"conversation_id\": conversation_id,\n",
        "                \"status\": \"pending\",\n",
        "                \"created_at\": time.time(),\n",
        "                \"final_response\": None\n",
        "            }\n",
        "            \n",
        "            return review_id\n",
        "        \n",
        "        def get_message(self, review_id):\n",
        "            return self.messages.get(review_id)\n",
        "        \n",
        "        def update_message(self, review_id, status, final_response=None):\n",
        "            if review_id in self.messages:\n",
        "                self.messages[review_id][\"status\"] = status\n",
        "                if final_response:\n",
        "                    self.messages[review_id][\"final_response\"] = final_response\n",
        "                self.messages[review_id][\"updated_at\"] = time.time()\n",
        "                return True\n",
        "            return False\n",
        "        \n",
        "        def get_pending_messages(self, limit=10):\n",
        "            pending = [\n",
        "                {\"review_id\": review_id, **message}\n",
        "                for review_id, message in self.messages.items()\n",
        "                if message[\"status\"] == \"pending\"\n",
        "            ]\n",
        "            \n",
        "            pending.sort(key=lambda x: x[\"created_at\"])\n",
        "            \n",
        "            return pending[:limit]\n",
        "    \n",
        "    message_queue = MessageQueue()\n",
        "    \n",
        "    class ChatRouter:\n",
        "        def __init__(self, message_queue, human_review_enabled=True, auto_approve_threshold=0.8):\n",
        "            self.message_queue = message_queue\n",
        "            self.human_review_enabled = human_review_enabled\n",
        "            self.auto_approve_threshold = auto_approve_threshold\n",
        "        \n",
        "        async def get_pending_reviews(self, limit=10):\n",
        "            return self.message_queue.get_pending_messages(limit)\n",
        "        \n",
        "        async def submit_human_review(self, review_id, approved, modified_response=None):\n",
        "            message = self.message_queue.get_message(review_id)\n",
        "            if not message:\n",
        "                return {\"error\": \"Message not found\"}\n",
        "            \n",
        "            final_response = modified_response if modified_response else message[\"ai_response\"]\n",
        "            \n",
        "            self.message_queue.update_message(\n",
        "                review_id=review_id,\n",
        "                status=\"approved\" if approved else \"rejected\",\n",
        "                final_response=final_response\n",
        "            )\n",
        "            \n",
        "            return {\"status\": \"success\", \"approved\": approved}\n",
        "    \n",
        "    chat_router = ChatRouter(message_queue, human_review_enabled, auto_approve_threshold)\n",
        "\n",
        "# Create a Jupyter widget interface for human review\n",
        "def create_human_review_interface():\n",
        "    \"\"\"Create a GUI for human review of AI responses.\"\"\"\n",
        "    # Header\n",
        "    header = widgets.HTML(\n",
        "        value=\"<h2>üß† Human-in-the-Loop Review Interface</h2>\"\n",
        "    )\n",
        "    \n",
        "    # Settings\n",
        "    human_review_toggle = widgets.Checkbox(\n",
        "        value=human_review_enabled,\n",
        "        description='Enable Human Review',\n",
        "        disabled=False,\n",
        "        indent=False\n",
        "    )\n",
        "    \n",
        "    threshold_slider = widgets.FloatSlider(\n",
        "        value=auto_approve_threshold,\n",
        "        min=0.0,\n",
        "        max=1.0,\n",
        "        step=0.05,\n",
        "        description='Auto-approve Threshold:',\n",
        "        disabled=False,\n",
        "        continuous_update=False,\n",
        "        orientation='horizontal',\n",
        "        readout=True,\n",
        "        readout_format='.2f',\n",
        "        style={'description_width': '180px'}\n",
        "    )\n",
        "    \n",
        "    settings_box = widgets.VBox([human_review_toggle, threshold_slider])\n",
        "    \n",
        "    # Pending messages list\n",
        "    pending_list = widgets.Select(\n",
        "        options=[],\n",
        "        description='Pending:',\n",
        "        disabled=False,\n",
        "        layout=widgets.Layout(width='100%', height='150px')\n",
        "    )\n",
        "    \n",
        "    # Message details\n",
        "    user_message = widgets.HTML(\n",
        "        value=\"<p><strong>User Message:</strong> Select a message to review</p>\"\n",
        "    )\n",
        "    \n",
        "    ai_response = widgets.Textarea(\n",
        "        value='',\n",
        "        placeholder='AI response will appear here. You can edit it.',\n",
        "        description='AI Response:',\n",
        "        disabled=False,\n",
        "        layout=widgets.Layout(width='100%', height='150px')\n",
        "    )\n",
        "    \n",
        "    confidence = widgets.HTML(\n",
        "        value=\"<p><strong>Confidence:</strong> N/A</p>\"\n",
        "    )\n",
        "    \n",
        "    # Action buttons\n",
        "    approve_button = widgets.Button(\n",
        "        description='Approve',\n",
        "        disabled=True,\n",
        "        button_style='success',\n",
        "        tooltip='Approve this response',\n",
        "        icon='check'\n",
        "    )\n",
        "    \n",
        "    reject_button = widgets.Button(\n",
        "        description='Reject',\n",
        "        disabled=True,\n",
        "        button_style='danger',\n",
        "        tooltip='Reject this response',\n",
        "        icon='times'\n",
        "    )\n",
        "    \n",
        "    refresh_button = widgets.Button(\n",
        "        description='Refresh',\n",
        "        disabled=False,\n",
        "        button_style='info',\n",
        "        tooltip='Refresh the pending list',\n",
        "        icon='refresh'\n",
        "    )\n",
        "    \n",
        "    status = widgets.HTML(\n",
        "        value=\"<p>Ready to review messages.</p>\"\n",
        "    )\n",
        "    \n",
        "    # Web interface link\n",
        "    web_interface_link = widgets.HTML(\n",
        "        value=f\"<p>Web interface available at: <a href='http://localhost:{server_port}/human-review' target='_blank'>http://localhost:{server_port}/human-review</a></p>\" if server_started else \"<p>Web server not started. Run Box 5 to enable web interface.</p>\"\n",
        "    )\n",
        "    \n",
        "    # Output area for debugging\n",
        "    output = widgets.Output()\n",
        "    \n",
        "    # Layout\n",
        "    buttons = widgets.HBox([approve_button, reject_button, refresh_button])\n",
        "    details = widgets.VBox([user_message, ai_response, confidence, buttons, status])\n",
        "    main_ui = widgets.VBox([header, settings_box, web_interface_link, pending_list, details, output])\n",
        "    \n",
        "    # Current review ID\n",
        "    current_review_id = None\n",
        "    \n",
        "    # Event handlers\n",
        "    async def refresh_pending_list(b=None):\n",
        "        with output:\n",
        "            clear_output()\n",
        "            print(\"Refreshing pending messages...\")\n",
        "        \n",
        "        pending_messages = await chat_router.get_pending_reviews()\n",
        "        \n",
        "        options = []\n",
        "        for message in pending_messages:\n",
        "            user_msg = message[\"message\"]\n",
        "            if len(user_msg) > 30:\n",
        "                user_msg = user_msg[:30] + \"...\"\n",
        "            options.append((f\"{message['review_id']}: {user_msg}\", message[\"review_id\"]))\n",
        "        \n",
        "        pending_list.options = options\n",
        "        \n",
        "        with output:\n",
        "            print(f\"Found {len(pending_messages)} pending messages.\")\n",
        "    \n",
        "    async def on_pending_selection(change):\n",
        "        nonlocal current_review_id\n",
        "        \n",
        "        if not change[\"new\"]:\n",
        "            return\n",
        "        \n",
        "        review_id = change[\"new\"]\n",
        "        current_review_id = review_id\n",
        "        \n",
        "        with output:\n",
        "            clear_output()\n",
        "            print(f\"Loading message {review_id}...\")\n",
        "        \n",
        "        message = message_queue.get_message(review_id)\n",
        "        \n",
        "        if not message:\n",
        "            with output:\n",
        "                print(f\"Message {review_id} not found.\")\n",
        "            return\n",
        "        \n",
        "        user_message.value = f\"<p><strong>User Message:</strong> {message['message']}</p>\"\n",
        "        ai_response.value = message[\"ai_response\"]\n",
        "        confidence.value = f\"<p><strong>Confidence:</strong> {message['confidence']:.2f}</p>\"\n",
        "        \n",
        "        approve_button.disabled = False\n",
        "        reject_button.disabled = False\n",
        "        \n",
        "        with output:\n",
        "            print(f\"Loaded message {review_id}.\")\n",
        "    \n",
        "    async def on_approve_clicked(b):\n",
        "        if not current_review_id:\n",
        "            return\n",
        "        \n",
        "        with output:\n",
        "            clear_output()\n",
        "            print(f\"Approving message {current_review_id}...\")\n",
        "        \n",
        "        result = await chat_router.submit_human_review(\n",
        "            review_id=current_review_id,\n",
        "            approved=True,\n",
        "            modified_response=ai_response.value\n",
        "        )\n",
        "        \n",
        "        status.value = f\"<p>‚úÖ Approved message {current_review_id}.</p>\"\n",
        "        approve_button.disabled = True\n",
        "        reject_button.disabled = True\n",
        "        \n",
        "        await refresh_pending_list()\n",
        "    \n",
        "    async def on_reject_clicked(b):\n",
        "        if not current_review_id:\n",
        "            return\n",
        "        \n",
        "        with output:\n",
        "            clear_output()\n",
        "            print(f\"Rejecting message {current_review_id}...\")\n",
        "        \n",
        "        result = await chat_router.submit_human_review(\n",
        "            review_id=current_review_id,\n",
        "            approved=False\n",
        "        )\n",
        "        \n",
        "        status.value = f\"<p>‚ùå Rejected message {current_review_id}.</p>\"\n",
        "        approve_button.disabled = True\n",
        "        reject_button.disabled = True\n",
        "        \n",
        "        await refresh_pending_list()\n",
        "    \n",
        "    def on_human_review_toggle(change):\n",
        "        new_value = change[\"new\"]\n",
        "        chat_router.human_review_enabled = new_value\n",
        "        \n",
        "        # Update config\n",
        "        config[\"human_review_enabled\"] = new_value\n",
        "        config_file = Path(\"./GoogleManusSystem/config/system_config.json\")\n",
        "        with open(config_file, \"w\") as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "        \n",
        "        with output:\n",
        "            clear_output()\n",
        "            print(f\"Human review {'enabled' if new_value else 'disabled'}.\")\n",
        "    \n",
        "    def on_threshold_change(change):\n",
        "        new_value = change[\"new\"]\n",
        "        chat_router.auto_approve_threshold = new_value\n",
        "        \n",
        "        # Update config\n",
        "        config[\"auto_approve_threshold\"] = new_value\n",
        "        config_file = Path(\"./GoogleManusSystem/config/system_config.json\")\n",
        "        with open(config_file, \"w\") as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "        \n",
        "        with output:\n",
        "            clear_output()\n",
        "            print(f\"Auto-approve threshold set to {new_value:.2f}.\")\n",
        "    \n",
        "    # Connect event handlers\n",
        "    pending_list.observe(lambda c: asyncio.create_task(on_pending_selection(c)), names='value')\n",
        "    approve_button.on_click(lambda b: asyncio.create_task(on_approve_clicked(b)))\n",
        "    reject_button.on_click(lambda b: asyncio.create_task(on_reject_clicked(b)))\n",
        "    refresh_button.on_click(lambda b: asyncio.create_task(refresh_pending_list(b)))\n",
        "    human_review_toggle.observe(on_human_review_toggle, names='value')\n",
        "    threshold_slider.observe(on_threshold_change, names='value')\n",
        "    \n",
        "    # Initial refresh\n",
        "    asyncio.create_task(refresh_pending_list())\n",
        "    \n",
        "    return main_ui\n",
        "\n",
        "# Create and display the human review interface\n",
        "human_review_interface = create_human_review_interface()\n",
        "display(human_review_interface)\n",
        "\n",
        "# Export configuration for other boxes\n",
        "box6_exports = {\n",
        "    \"human_review_enabled\": human_review_enabled,\n",
        "    \"auto_approve_threshold\": auto_approve_threshold\n",
        "}\n",
        "\n",
        "box6_exports_file = Path(\"./GoogleManusSystem/config/box6_exports.json\")\n",
        "with open(box6_exports_file, \"w\") as f:\n",
        "    json.dump(box6_exports, f, indent=2)\n",
        "\n",
        "print(\"\\nüéâ BOX 6 SETUP COMPLETED SUCCESSFULLY!\")\n",
        "print(\"üë§ Human-in-the-Loop System Initialized\")\n",
        "print(f\"üîÑ Human Review: {'Enabled' if human_review_enabled else 'Disabled'}\")\n",
        "print(f\"üî¢ Auto-approve Threshold: {auto_approve_threshold:.2f}\")\n",
        "if server_started:\n",
        "    print(f\"üåê Web Interface: http://localhost:{server_port}/human-review\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}